{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "root_path = '/Users/u6066091/Desktop/kaggle/input/corona_challenge/'\n",
    "\n",
    "corona_features = {\"doc_id\": [None], \"source\": [None], \"title\": [None],\n",
    "                  \"abstract\": [None], \"text_body\": [None]}\n",
    "corona_df = pd.DataFrame.from_dict(corona_features)\n",
    "\n",
    "json_filenames = glob.glob(f'{root_path}/**/*.json', recursive=True)\n",
    "\n",
    "# from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/u6066091/Desktop/kaggle/input/corona_challenge/custom_license/86a998617c077f4fe2ab26214995a3548fbc0fc5.json'"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_corona_df(json_filenames, df):\n",
    "\n",
    "    for file_name in json_filenames:\n",
    "\n",
    "        row = {\"doc_id\": None, \"source\": None, \"title\": None,\n",
    "              \"abstract\": None, \"text_body\": None}\n",
    "\n",
    "        with open(file_name) as json_data:\n",
    "            data = json.load(json_data)\n",
    "\n",
    "            doc_id = data['paper_id']\n",
    "            row['doc_id'] = doc_id\n",
    "            row['title'] = data['metadata']['title']\n",
    "\n",
    "            # Now need all of abstract. Put it all in \n",
    "            # a list then use str.join() to split it\n",
    "            # into paragraphs. \n",
    "\n",
    "            abstract_list = [abst['text'] for abst in data['abstract']]\n",
    "            abstract = \"\\n \".join(abstract_list)\n",
    "\n",
    "            row['abstract'] = abstract\n",
    "\n",
    "            # And lastly the body of the text. \n",
    "            body_list = [bt['text'] for bt in data['body_text']]\n",
    "            body = \"\\n \".join(body_list)\n",
    "            \n",
    "            row['text_body'] = body\n",
    "            \n",
    "            # Now just add to the dataframe. \n",
    "            \n",
    "#             if source == 'b':\n",
    "#                 row['source'] = \"BIORXIV\"\n",
    "#             elif source == \"c\":\n",
    "#                 row['source'] = \"COMMON_USE_SUB\"\n",
    "#             elif source == \"n\":\n",
    "#                 row['source'] = \"NON_COMMON_USE\"\n",
    "#             elif source == \"p\":\n",
    "#                 row['source'] = \"PMC_CUSTOM_LICENSE\"\n",
    "            \n",
    "            df = df.append(row, ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "corona_df = return_corona_df(json_filenames, corona_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['doc_id', 'source', 'title', 'abstract', 'text_body'], dtype='object')"
      ]
     },
     "execution_count": 968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corona_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corona_out = corona_df.to_csv('/Users/u6066091/Desktop/kaggle/output/corona_challenge/four_source.csv')\n",
    "# metadata = pd.read_csv('/Users/u6066091/Desktop/kaggle/scimagoj_2018.csv', sep = ' ;')\n",
    "metadata = pd.read_csv('/Users/u6066091/Desktop/kaggle/input/corona_challenge/metadata.csv')\n",
    "# root_path = '/Users/u6066091/Desktop/kaggle/output/corona_challenge/'\n",
    "# extension = 'csv'\n",
    "# all_filenames = [i for i in glob.glob(f'{root_path}/**/*.csv', recursive=True)]\n",
    "# all_4 = pd.concat([pd.read_csv(f) for f in all_filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cord_uid', 'sha', 'source_x', 'title', 'doi', 'pmcid', 'pubmed_id',\n",
       "       'license', 'abstract', 'publish_time', 'authors', 'journal',\n",
       "       'Microsoft Academic Paper ID', 'WHO #Covidence', 'has_full_text',\n",
       "       'full_text_file', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 933,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = pd.merge(all_data,\n",
    "#                  metadata,\n",
    "#                  on='title', \n",
    "#                  how='left')\n",
    "# new_data.to_csv('/Users/u6066091/Desktop/kaggle/output/corona_challenge/all_data_metadata.csv')\n",
    "# new_data = pd.read_csv('/Users/u6066091/Desktop/kaggle/output/corona_challenge/all_data_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'doc_id', 'source', 'title', 'abstract_x', 'text_body',\n",
       "       'sha', 'source_x', 'doi', 'pmcid', 'pubmed_id', 'license', 'abstract_y',\n",
       "       'publish_time', 'authors', 'journal', 'Microsoft Academic Paper ID',\n",
       "       'WHO #Covidence', 'has_full_text', 'full_text_file'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv('risk_covid_summary.csv')\n",
    "endre = pd.merge(summary, new_data, on = 'title', how ='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we know about COVID-19 risk factors?\n",
    "The hypothesis is that if a paper's abstract has risk and Covid words together, it talks about Covid-19 risk factor. This approach, hopefully, is more targeted at high recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_ind = []\n",
    "count_risk = []\n",
    "abst_risk = []\n",
    "abstract = list(corona_df['text_body'])\n",
    "for i in abstract:\n",
    "    if (str(i).lower().find('smok') != -1 or str(i).lower().find('pulm') != -1 and str(i).lower().find('covid') != -1):\n",
    "#  risk_covi.csv    if (str(i).lower().find('risk') != -1 or str(i).lower().find('covi') != -1 ):\n",
    "        abst_risk.append(i)\n",
    "        count_risk.append(i.lower().count('covid')+ i.lower().count('pulm')/len(i.lower()))\n",
    "corona_df_risk_covid = corona_df[corona_df['text_body'].isin(abst_risk)] \n",
    "# corona_df_risk_covid['count_risk'] = count_risk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "corona_df_risk_covid['count_risk'] = count_risk\n",
    "\n",
    "corona_df_risk_covid = corona_df_risk_covid.sort_values('count_risk', ascending = False).drop_duplicates('title').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text_body</th>\n",
       "      <th>count_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320e1640a5ddfcbed21e1afff08a86dc1b0af5b2</td>\n",
       "      <td>None</td>\n",
       "      <td>Cardiovascular Considerations for Patients, He...</td>\n",
       "      <td></td>\n",
       "      <td>First appearing in Wuhan, China, the coronavir...</td>\n",
       "      <td>65.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e38333bff68345492526fd39b70d1b18969cb83</td>\n",
       "      <td>None</td>\n",
       "      <td>Deep Learning-based Detection for COVID-19 fro...</td>\n",
       "      <td>Accurate and rapid diagnosis of COVID-19 suspe...</td>\n",
       "      <td>huge amount of efforts for radiologists, which...</td>\n",
       "      <td>62.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9e0f7bae6dd63db5ccf38bd90d3337c72eb7958a</td>\n",
       "      <td>None</td>\n",
       "      <td>Development and Evaluation of an AI System for...</td>\n",
       "      <td>Early detection of COVID-19 based on chest CT ...</td>\n",
       "      <td>The new coronavirus disease, now known as COVI...</td>\n",
       "      <td>61.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5307fbd7cbc9b0b7e87ec4d1a8b99e544d81446f</td>\n",
       "      <td>None</td>\n",
       "      <td>The epidemiology and pathogenesis of coronavir...</td>\n",
       "      <td></td>\n",
       "      <td>Coronavirus is one of the major pathogens that...</td>\n",
       "      <td>48.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15bad8368522a05f32dee771e5a8259f0e9cbbfd</td>\n",
       "      <td>None</td>\n",
       "      <td>Title: The SARS-CoV-2 exerts a distinctive str...</td>\n",
       "      <td>The COVID-19 disease has plagued over 110 coun...</td>\n",
       "      <td>To gain access to host cells, coronaviruses re...</td>\n",
       "      <td>46.000069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     doc_id source  \\\n",
       "0  320e1640a5ddfcbed21e1afff08a86dc1b0af5b2   None   \n",
       "1  0e38333bff68345492526fd39b70d1b18969cb83   None   \n",
       "2  9e0f7bae6dd63db5ccf38bd90d3337c72eb7958a   None   \n",
       "3  5307fbd7cbc9b0b7e87ec4d1a8b99e544d81446f   None   \n",
       "4  15bad8368522a05f32dee771e5a8259f0e9cbbfd   None   \n",
       "\n",
       "                                               title  \\\n",
       "0  Cardiovascular Considerations for Patients, He...   \n",
       "1  Deep Learning-based Detection for COVID-19 fro...   \n",
       "2  Development and Evaluation of an AI System for...   \n",
       "3  The epidemiology and pathogenesis of coronavir...   \n",
       "4  Title: The SARS-CoV-2 exerts a distinctive str...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0                                                      \n",
       "1  Accurate and rapid diagnosis of COVID-19 suspe...   \n",
       "2  Early detection of COVID-19 based on chest CT ...   \n",
       "3                                                      \n",
       "4  The COVID-19 disease has plagued over 110 coun...   \n",
       "\n",
       "                                           text_body  count_risk  \n",
       "0  First appearing in Wuhan, China, the coronavir...   65.000247  \n",
       "1  huge amount of efforts for radiologists, which...   62.000094  \n",
       "2  The new coronavirus disease, now known as COVI...   61.000109  \n",
       "3  Coronavirus is one of the major pathogens that...   48.000057  \n",
       "4  To gain access to host cells, coronaviruses re...   46.000069  "
      ]
     },
     "execution_count": 991,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corona_df_risk_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Respiratory infections are common and one of the leading causes of morbidity and mortality, particularly in the extremes of age [1] [2] [3] . Influenza A and B, human rhinoviruses (HRV), respiratory syncytial virus (RSV), adenoviruses (ADV) and parainfluenza virus (PIV) are common respiratory viruses in adults and children [1] [2] [3] [4] [5] . Of respiratory infections, influenza is the most well studied viral infection, and is commonly reported (around 50%) as the cause of epidemics of respiratory infection, including nosocomial outbreaks [6] . Influenza virus is commonly isolated from febrile paediatric and elderly patients presenting with influenza-like illness (ILI) and acute respiratory illness (ARI) symptoms [1] . The accepted clinical case definition of ILI includes fever, which may be suitable for identifying paediatric cases, but less so for adults.\\n Fever is thought of as the most common presenting symptom of influenza in hospital emergency departments; however, the presence of fever depends on the age of person and the type of virus [7] [8] [9] [10] . It is known that fever is less common in adults than children with influenza, and that adults may have atypical presentations [5, 6, 11] . In a matched case-control study in Finland, 317 laboratoryconfirmed influenza cases and 353 controls with respiratory symptoms were recruited in children aged 413 years. Fever was present in 89·8% (317/353) and 35·7% (126/353) of cases and controls, respectively [12] . In contrast to this, fever is not a common presentation in adults with laboratory-confirmed influenza. Monto et al. [13] examined clinical trial data of 3744 adult ILI cases (defined as body temperature 537·8°C or patients subjective feeling of feverishness) and of those 2470 (66%) had laboratory-confirmed influenza. Fever (537·8°C) was reported in 68% of laboratory-confirmed influenza cases, compared to 40% other ILI cases [13] . During a randomized clinical trial (RCT) around the efficacy of facemask and hand hygiene in the household setting, 44% (15/34) of secondary cases with influenza A and 32% (8/ 25) of cases with influenza B had fever history [14] . The rate of fever was 66% (137/207) in hospitalized influenza cases in a US study [15] . Another US study showed that less than half (42·4%) of healthcare workers (HCWs) with laboratory-confirmed influenza presented with fever [5] . Fever is a less common presenting symptom in elderly people which may lead to diagnostic and treatment delays [16] . In patients admitted with myocardial infarction, 9% had unrecognized and undiagnosed influenza on testing at admission, highlighting the low level of clinical suspicion of influenza [17] .\\n The rate of fever also varies between influenza strains, being more common in influenza A strains than B, and higher in H3N2 [7] [8] [9] [10] 18] . Fever is a commonly reported symptom during influenza outbreaks and pandemics due to novel and more virulent nature of strains. In China 67·4% of the patients infected by influenza A(H1N1)pdm09 had fever [19] . In another study in Beijing 465 suspected ILI cases were tested and of those 318 (68%) were positive for influenza virus (pandemic H1N1-165 and seasonal influenza H3N2-153) and all had history of fever [20] .\\n The aim of this study was to compare the rates of fever in adult subjects with confirmed influenza and other respiratory virus infections and examine predictors of fever.\\n We analysed a dataset of laboratory-confirmed viral respiratory infections collected from three clinical trials of HCWs where active surveillance for respiratory viral illness was conducted in prospective follow up [21] [22] [23] . The same methods, data collection forms and outcome measures, were used across the three studies, allowing the data to be pooled [21] [22] [23] . Two studies were conducted in Beijing China: trial 1 (2008/2009) and trial 2 (2009/2010) and another study (trial 3) was conducted in Hanoi, Vietnam in 2010/2011 [21] [22] [23] . In all clinical trials, participants were asked to complete diary cards on a daily basis to collect information on number of working hours, patients seen, mask use hours, high-risk procedures performed and appearance of respiratory symptoms. Thermometers were given the participants to measure their temperature daily and at symptom onset. Symptomatic cases were asked to complete sick patient follow-up forms and detailed information was collected on the following symptoms: chill or fever, cough, congestion, runny nose, sore throat, sneezes, lethargy, loss of appetite, abdominal pain, muscle or joint aches. Swabs of both tonsils and the posterior pharyngeal wall were collected on the day of reporting.\\n In all RCTs, fever was defined as having body temperature 538°C. Clinical respiratory illness (CRI) and ILI were in the primary outcomes in three clinical trials. CRI was defined as two or more respiratory symptoms or one respiratory symptom and a systemic symptom and ILI was defined as fever 538°C plus one respiratory symptom [21] [22] [23] .\\n We analysed data from all subjects with a positive isolation of a respiratory virus by multiplex polymerase chain reaction (PCR). Descriptive analysis was conducted for rates of fever by virus type. A logistic regression analysis was used to determine the predictors of fever. A multivariable log binomial model was fitted, using a generalized linear model to estimate relative risk (RR). All variables were included in initial model. In the final model, we included only those variables that were significant (P < 0·25) in initial analysis. A backward elimination method was used to remove the variables that did not have any confounding effect, i.e. could not make meaningful change (±10%) in the RR of the comparison arm. Finally we estimated the rates of CRI and ILI in the laboratory-confirmed viral respiratory infections and laboratory-confirmed influenza infections. The data was analysed using SAS v. 9.4 (SAS Institute Inc., USA). \\n The demographic characteristics of 158 cases with laboratory-confirmed viral infections are presented in Table 1 . Ninety (57%) cases were from China and 68 (43%) were from Vietnam. The mean age of HCWs was 32·8 years and most participants were nurses (65%) and female (87%). Most cases were non-smokers (92%) and had not received influenza vaccine (86%). Viruses isolated included rhinovirus (n = 75, 47%), RSV (n = 28, 18%), influenza (n = 13, 8%), PIV (n = 12, 8%), human metapneumovirus (hMPV; n = 7, 4%), coronavirus (n = 7, 4%) and ADV (n = 1, 1%). More than one virus was isolated in 15 cases (9·5%), including nine cases with influenza co-infection. Fever was documented in 23·4% cases (37/158) with a positive laboratory viral diagnosis. Table 2 details rates of fever (538°C) associated with individual viral respiratory infections. HRV was the most common infection and 25·3% (19/75) of these had a fever. In 28 cases of RSV, four (14·3%) had fever; 8·3% (1/12) of PIV and 30% (3/10) of influenza A cases had fever. Seven cases of coronavirus and hMPV each were confirmed and of those two (28·6%) had fever. When cases with influenza and a co-infection were included, 36·4% (8/22) had fever. In univariate analysis, country, gender and smoking were significant predictors of fever. Country and smoking remained significant predictors in multivariate analysis while gender became non-significant. Fever rate was significantly higher in HCWs in Vietnam compared to HCWs in China [RR 2·99, 95% confidence interval (CI) 1·24-7·20]. Smokers were around five times more likely to have fever compared to non-smokers (RR 4·65, 95% CI 1·33-16·25). Virus type was not associated with fever in univariate analysis; however, after adjusting for other variables, rates of fever were significantly higher in HCWs co-infected with more than one virus compared to all other viruses excluding influenza (RR 4·19, 95% CI 1·21-14·52) ( Table 3) .\\n CRI symptoms were present in 84·8% (137/158) of HCWs with laboratory-confirmed viral infections and 90·9% (20/22) laboratory-confirmed influenza infections. The corresponding rates of ILI in the two groups were 9·5% (15/158) and 13·6% (3/22), respectively.\\n We have shown, using prospectively collected data, that the rate of fever in adults with confirmed viral respiratory infections is much lower than described in children [1, 9] . The standard clinical case definition of ILI requires fever to be presentthe majority of influenza cases in this series would have been missed using the ILI definition. This has implications for effective triage, early antiviral treatment and preventive measures for adults with influenza, particularly during outbreaks and pandemic situations. For other respiratory infections, clinical case definitions need to be more sensitive, or >75% of cases will be missed. The main implication for future surveillance, measurements and research studies is that the ILI case definition in adults may be highly insensitive. For some types of surveillance systems, this may not be an issue, but for diagnostic screening in event of an emerging viral infection (such as for triage and implementation of infection control protocols) [24, 25] , a more sensitive case definition is needed.\\n Rates of fever in influenza and other viral respiratory infections in this study were lower compared to other studies which report fever in around 50-70% adult cases [1, 5, 13, 15] . However, this variation may be due to different study base, case definition and viral strains, as well as the prospective measurement of incident infections. Many research studies use fever as an inclusion criterion for laboratory testing [13, 26] . While this may be suitable for studies in children, it is not adequately sensitive for studies of adults, as we have shown the majority of confirmed cases will be missed. The cut-off point for fever could be another factor in sensitivity. Some studies have set lower cut-off points for fever, and report higher rates of fever in laboratory-confirmed influenza cases [13, 27] . Carrat et al. collected data of cases presented in 35 general practices in France and collected nasal swabs from suspected influenza cases and defined fever as 537·8°C. They found fever in influenza A(H3N2), influenza A(H1N1) and influenza negative cases in 95·2%, 77·5% and 72·7%, respectively. Applying a cut-off of 538·2°C, the corresponding rates are 82·2%, 59·3% and 43·9% [27] . Symptoms of feverishness (subjective feeling of fever) are included in ILI definitions in some cases [13] .\\n Previous studies report high rates of fever in children compared to the adults [11] . Low rates of fever in adults may also be due to protection via cross-reactive antibodies due to age-dependent differences in the immunity [7, 28] . Continued exposure to influenza throughout life may result in a broader protection with age. Infection may provoke a stronger immune response in children with minimal to no exposure history compared to adults. Therefore influenza infection history might help explain potential differences in clinical symptom severity (and presence of fever) between children and adults.\\n A recent study reported high rates of influenza and other respiratory virus in afebrile HCWs with only respiratory symptoms [5] . Of 22 laboratory-confirmed influenza cases in this study, only three (13·6%) had ILI symptoms, which is very low compared to other studies. In a prospective influenza surveillance study, ILI symptoms were present in 48% of adults and 61% of children with laboratory-confirmed influenza virus [1] . CRI symptoms were present in 90·9% (20/22) of laboratory-confirmed influenza cases in this study.\\n A highly sensitive definition of influenza may be required to diagnose most of adult influenza cases in the clinical setting to ensure rapid treatment and isolation, and prevention of nosocomial transmission. Inclusion of ILI cases may overestimate the proportion of febrile cases in influenza surveillance given fever is included in the definition. Pre-symptomatic and asymptomatic influenza cases will also be missed, although infectivity and transmissibility of these cases is yet to be proven [29] . Longitudinal studies, where all participants are tested, provide similar estimates around rates of fever as in our study [14] . We propose a more sensitive clinical case definition without fever as a requisite criterion.\\n Clinical signs and symptoms are less studied for other viral respiratory infections, but available evidence suggests that other respiratory viruses are associated with a lower rate of fever compared to influenza [5, [30] [31] [32] [33] . Putto and colleagues [30] examined the clinical records of 258 children (>3 months) in a large hospital in Finland, including ADV (25 cases), influenza A and B (74 cases), PIV (99 cases) and RSV (60 cases). Fever (539·0°C) was recorded in 68% cases with ADV, 84% influenza A virus, 65% influenza B, 41% PIV-1, 50% PIV-2, 47% PIV-3, and 52% RSV. Van den Hoogen and colleagues estimated the prevalence and clinical symptoms of hMPV infection, in The Netherlands and fever was reported in 61% of the hMPV-positive cases [31] . In Hong Kong, hMPV was found in 5·5% (32/587) of children admitted in hospitals and all had fever [32] . Manoha et al. examined nasal wash specimens from 931 hospitalized children and found hMPV (6%), RSV (28·5%), rhinoviruses (18·3%), influenza A (6%), PIV-1 (0·2%) and PIV-3 (0·3%). Fever was reported in 39·2% cases with hMPV, 37·8% cases with RSV and 30·2% with rhinovirus [33] . Of the 210 elderly patients with influenza and 145 with RSV, fever was reported in 65% and 50%, respectively [3] . A US study also reported low rates of fever in HCWs infected with coronavirus 229E (13·5%), coronavirus HKU (11·4%), coronavirus NL63 (31·3%) and RSV (12·9%) and all cases of hMPV were without fever [5] . Rate of fever for all other viruses (excluding influenza) was 21·5% (28/130) in this study.\\n Co-infection with more than one virus was the strongest predictor of fever for adults with confirmed viral respiratory infections in the present study. Previous studies also show high rates of fever in cases with dual respiratory viral infections compared to single viral infection [34, 35] . Rates of hospitalization and ICU admission are also reported to be higher in cases with dual respiratory viral infections [36] [37] [38] . Increased severity of symptoms in co-infection cases might be due to an altered immune response [34] . Around 10% (15/158) of cases in our dataset were infected with more than one virus. Drews et al. reviewed the data of eight prospective epidemiological studies and reported the rate of co-infection was 5% [37] . Studies in children generally report higher rates of co-infection cases (17-20%) [34, 35, 38, 39] . Clinicians should consider the possibly of co-infection if a patient presents with fever; however, further epidemiological and clinical studies are required.\\n Smoking was also a significant predictor of fever in this study. Smoking increases the risk of viral and bacterial infections through changes in respiratory epithelial and altered immune response [40] [41] [42] [43] .The risk of influenza also increases several times in smokers, compared to non-smokers [40] . Atypical clinical presentation of influenza and other respiratory infections in adults could be due to altered structural and immune response associated with active/passive smoking and other environmental hazards. The mechanism by which smoking increases the risk of fever is not clear. High rates of fever in smokers may also be due changes in immunoglobulin levels which could increase viral load. The severity of symptoms generally increases when high viral load is detected in the blood [44] .\\n The difference in fever rates between China and Vietnam may be due to prevalence of viruses and co-infection. RSV was the most commonly isolated pathogen from China (31%), followed by rhinovirus (20%) and influenza virus (13%). In contrast to this HRV was the most commonly isolated pathogen from Vietnam (85·3%). The number of cases with co-infection were also different in the two countries -13 (14%) in China and two (3%) in Vietnam. In multivariate analysis, we adjusted for country and type of virus. Limited data are available regarding the prevalent viruses circulating in China during the study period. For the trial 1 period, all influenza was influenza A(H1N1)pdm. For the trial 2 period, 21·3% were H1N1pdm, 2·9% were H3N2, 3·0% were influenza B Victoria, 2·6% were influenza B Yamagata, 71·2% were influenza A unsubtyped (Y. Zhang, Beijing Centre for Disease Prevention and Control, personal communication). We could not obtain data on the viruses circulating in Vietnam during the study period.\\n There are some limitations to this study. We did not subtype the influenza strains, and studies show that the rate of fever also varies between influenza strains [7] [8] [9] [10] 18] . Fever data was self-reported but self-measured in three trials using a traditional glass and mercury thermometer. Lower fever rates in Chinese HCWs in this study might be due to due to differences in circulating viruses (and their pyrogenicity) between the two countries when the studies were conducted. A Japanese study of children with influenza reported a tendency towards shorter duration of fever with increasing age in children [18] ; however, age and other demographic characteristics were not significant in that study.\\n Compared to children, this study shows that adults are less likely to have fever with a respiratory viral infection, even influenza. The implication of this finding is that for rapid treatment and reducing the risk of transmission of infection, clinicians should be aware that a diagnosis of viral respiratory infection, even influenza, is possible in the absence of fever. Many of these infections are transmissible even when infected persons are asymptomatic or presymptomatic, and greater vigilance for respiratory symptoms in HCWs could reduce nosocomial transmission of respiratory viral infections. The absence of fever should not preclude a differential diagnosis of influenza or other respiratory viruses in adults.'"
      ]
     },
     "execution_count": 912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_journal = list(new_data['journal'].unique())\n",
    "#which journals are about epidemiology\n",
    "journal_of_epi = [str(i) for i in list_of_journal if 'epi' in str(i).lower() ]\n",
    "corona_df_risk_covid[corona_df_risk_covid['journal'].isin(journal_of_epi)].loc[0,'text_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"First appearing in Wuhan, China, the coronavirus disease of 2019 is caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV2) (1, 2) . Given the rapid spread of this virus with consequences on an international scale, COVID-19 was declared a pandemic by the World Health\\n Organization on March 11 th 2020 (2) . It is imperative that health care workers and researchers across all disciplines be aware of the potential impact that this disease can have on their respective fields and the medical community at large (3) .\\n Based on currently observed disease patterns, cardiovascular (CV) specialists will be actively engaged in the care of patients with COVID-19. The infection may directly impact cardiovascular disease (CVD). Preexisting cardiovascular disease (CVD) may predispose to COVID-19 infection. Those with CVD who are infected by the virus have an elevated risk of adverse outcomes; and infection, itself, is associated with cardiovascular complications (4) (5) (6) . Moreover, COVID-19 infection may also have numerous indirect effects relevant to CV health. The large numbers of infected people requiring care may impact optimal treatment delivery to patients with acute CV conditions. Therapeutics for COVID-19 have the potential for adverse CV effects and clinicians delivering CV care are at risk of developing the illness or become vectors for the infection. The objective of this review is to characterize the CV impact of COVID-19, its potential consequences in patients with established CVD, as well as considerations for individual patients (with and without COVID- 19) , health care workers, and health systems, as understanding and addressing these issues will be crucial to optimize outcomes during the current critical period and beyond.\\n Given the time-sensitive nature of the challenges associated with this outbreak, we reviewed the published literature (including multiple search strategies in MEDLINE with PubMed interface) and\\n critically assessed early reports on medRxiv, a pre-print server (https://www.medrxiv.org/) (date of last search: March 16, 2020) . Since the initial epicenter for this outbreak was from China, the majority of data on patients with COVID-19 are from this region. Although a systematic attempt was made to include reports and viewpoints from other heavily affected countries, data related to CV risk factors or presentation were limited. This is important, since the testing strategies, care seeking behavior, and hospitalization thresholds vary in different settings and can bias numerators and denominators, influencing estimates of the impact of the virus. This selection bias in testing, care and reporting can lead to differences in prevalence estimates of pre-existing risk factors and patient presentation across the reports from various countries. Further, the majority of the existing analyses, including those related to CV complications of COVID-19 are based on retrospective and often single-center series. Accordingly, data elements were usually reported via chart review, without external prospective ascertainment. No published or completed prospective cohort studies or randomized controlled trials were present in this literature search. These issues have important implications for research priority setting, and for interpretations of the results reported herein. There is an urgent need for high quality research in this area, but at this point it is useful to review the available data.\\n SARS-CoV2, like other members of the Coronaviridae family, is an enveloped virus with nonsegmented, single stranded, positive-sense RNA genome (1, 7) . A number of SARS-related coronaviruses have been discovered in bats, and a working theory is that bats may have been the initial zoonotic host for SARS-CoV2 given that its genome is 96.2% identical to a bat coronavirus (8) . Studies have demonstrated that SARS-CoV2 as well as other coronaviruses can use the angiotensin-converting enzyme 2 (ACE2) protein for cell entry. ACE2 is a type I integral membrane protein which serves many important physiologic functions. It is highly expressed in lung alveolar cells, providing the main entry site for the virus into human hosts (8, 9) . After ligand binding, SARS-CoV2 enters cells via receptor-mediated endocytosis in a manner akin to human immunodeficiency virus (HIV) (10) . ACE2 also serves a role in lung protection and therefore viral binding to this receptor deregulates a lung protective pathway, contributing to viral pathogenicity (11) . Figure 1 depicts the potential mechanisms for ACE2 with regard to viral pathogenicity and lung protection, as well as the potential effects on this from renin-angiotensinaldosterone inhibition as noted in the section on Drug Therapy and COVID-19 below.\\n Since initial identification, the disease has spread to over 100 countries across the world (1). As of March 16, 2020 at 11:53AM, there have been a total of 174,961 COVID-19 cases reported globally (3, 813 in the United States) associated with 6,705 deaths thus far (69 in the United States), resulting in a crude case-fatality rate of 3.8% (12, 13) . Johns Hopkins University is making current data available:\\n https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6 (12) . The infectivity of COVID-19 is greater than that of influenza, with an estimated R 0 value (the basic reproduction number, representing viral infectivity) of 2.28 (14) . Notably, the death rate associated with COVID-19 is also considerably higher compared with the most recent WHO estimate of seasonal influenza mortality rate of less than 0.1%, and may reach much higher rates in elderly patients, those with comorbidities, and absent efficient intensive care support (13) . While other zoonotic coronaviruses, including the 2002-2003 severe acute respiratory syndrome (SARS) epidemic and the Middle East respiratory syndrome (MERS-CoV), had higher associated case fatality rates of 9.6% and 34.4%, respectively (15), COVID-19 has resulted in many more deaths than both of these prior outbreaks combined, an issue that is in part related to the greater infectivity and higher attack rate of this virus, leading to a larger number of infected patients (15, 16) . Uncertain and inconsistent disease ascertainment have resulted in variability in reported case fatality rates for several reasons, including: 1) the disease may be asymptomatic or mildly symptomatic in a large proportion of patients (15) , 2) inadequate testing capabilities in most geographies, leading to frequent underdiagnosis, especially in patients with less serious illness, and 3) complications and death often ensue much later than contagion (typically between 2 and 3 weeks after infection). Notably, the appraisal of SARS-CoV-2 infection may be further complicated by asymptomatic infection in a sizable portion of individuals (as many as 20%), which may significantly contribute to further spread of infection (17) The (18), although knowledge of the clinical feature of the disease is evolving daily (1, 19) . In severe cases, COVID-19 may present as pneumonia, the acute respiratory distress syndrome (ARDS), with or without both distributive and cardiogenic shock, to which elderly populations with preexisting medical comorbidities are the most vulnerable (1, 6, 19, 20) . Notably while rates of concomitant infections with other viruses and bacterial superinfections in preliminary data appear low (15) , patients with the most severe clinical presentations are likely still at risk for co-infections, and unsurprisingly, worse outcomes have been noted in such cases (20, 21) . Children account for the minority of laboratory-confirmed cases of COVID-19 in China and appear to be less susceptible to severe disease, possibly due to stronger innate immunity, fewer comorbidities, differences in maturation of viral receptors, and/or prior exposure to other coronavirus species (22) . However, moderate-to-severe illness has been described in children as well (23) . Moreover, it is not clear how often children were being tested.\\n Since an extremely large and increasing number of patients have been diagnosed with COVID-19, identification of prognostic factors associated with morbidity and mortality are crucial. To date, no approved preventative vaccines or approved therapies are available for COVID-19, although several are being actively studied (24) .\\n The lack of widespread testing, national surveillance and standardized data collection, as well as the potential sampling bias in sicker, hospitalized patients with more comorbidities such as CVD has complicated efforts to accurately estimate the prevalence of CVD in patients with COVID-19. Moreover, there is marked variation in testing by country. A number of studies in the available literature suggest an association between preexisting CVD and severe COVID-19, which are summarized in Tables 1 and 2 . A meta-analysis of six studies inclusive of 1,527 patients with COVID-19 examined the prevalence of CVD and reported the prevalence of hypertension, cardiac and cerebrovascular disease, and diabetes to be 17.1%, 16.4%, and 9.7%, respectively (4). Patients who required intensive care unit (ICU) admission were more likely to have these comorbidities compared to non-ICU patients. Increased case-fatality rates in the previously referenced analysis of 44,672 confirmed COVID-19 cases from Wuhan, China were noted in patients with CVD (10.5%), diabetes (7.3%), hypertension (6.0%), all notably higher than the overall case-fatality rate of 2.3% (15) . Several smaller cohort studies have yielded similar results suggesting higher risk for adverse events in patients with CVD who contract COVID-19, although biases related to testing and standardized data apply here as well (1, 19, (25) (26) (27) (28) . Notably, while reports outside of China are limited, data from Italy suggest similar mortality rates and an elevated risk for death in patients with comorbidities (29) . As emerging international data become available, analysis from multinational cohorts can help inform risk stratification for severe disease especially for patients with prior CVD.\\n Mechanisms that lead to CVD are increasingly recognized to overlap with pathways that regulate immune function. For instance, age is the strongest risk factor for CVD and the effect of aging on immune function may be equally important for COVID-19 suceptibility and severity. Exemplary of this, the effect of age on the immune system is exemplified by low protective titers among 50% of adults older than 65 who receive the influenza vaccine (30, 31) . Other traditional CVD risk factors such as diabetes and hyperlipidemia impact immune function, and conversely, dysregulated immunologic status corresponds with elevated risk of incident CVD (32) (33) (34) (35) . Thus, prevalent CVD may be a marker of accelerated immunologic aging/dysregulation and relate indirectly to COVID-19 prognosis. An increased frequency of adverse CVD events post COVID-19 infection might also play a role in prognosis, similar to other viral infections such as influenza with mechanistic underpinnings which are complex, multi-factorial, and bi-directional (36, 37) . In addition, COVID-19 infection may trigger pathways unique to this pathogen which contribute to outcomes in CVD patients. For instance, higher expression of ACE2 in patients with hypertension and CVD has been postulated to enhance susceptibility to SARS-CoV2, although the data are conflicting and without clear suggestion for treatment ( Figure 1 ) (5) . Additional study is needed to understand the potential mechanistic relationships between CVD and COVID-19 outcomes.\\n In addition to the mechanisms by which COVID-19 can affect patients with CVD risk factors, it is also important to consider COVID-19 in the context of an especially vulnerable group of patients, such as individuals awaiting or post heart transplantation. There are now case reports of COVID-19 infection among heart transplant patients (38, 39) .Two heart transplant patients in China, one with mild and one with severe disease, presented with symptoms typical of COVID-19 disease. Both were managed by withholding baseline immunosuppressive regimens and treating aggressively with high dose steroids, intravenous immunoglobulin, and antibiotics, and both survived without evidence of allograft rejection.\\n Previous viral outbreaks have noted particularly severe infection in immunosuppressed solid organ transplant recipients (40) . Formal treatment guidelines in these patients do not exist at this time. Heart allocation teams need to consider the optimal screening strategies in order to prevent severe infection in recipients including whether all donor hearts should be screened, given the existence of asymptomatic COVID-19, versus limiting screening to patients with a history of symptoms or exposure of COVID-19.\\n During the H1N1 influenza pandemic, potential donors were screened if symptomatic or if they had significant exposure history in order to prevent infection in the recipient or as an impetus to initiate prophylaxis if the donor was positive (41) . Similarly, screening recipients for a history of symptoms or exposure of COVID-19 to avoid a post-transplant flare will be reasonable to be considered. Utmost precautions in infection control must be employed when interacting with these vulnerable immunosuppressed patients. \\n Myocardial injury, as defined by an increased troponin level, can occur due to myocardial ischemia or non-ischemic myocardial processes including myocarditis (6, 42, 43) . With severe respiratory infection and hypoxia, especially in the setting of severe infection and ARDS due to COVID-19, it is likely that a number of patients will develop such injury. Elevated serum troponin levels have been described in many patients infected with COVID-19, with significant differences noted between patients who died and those who survived to discharge (21, 44) . In a meta-analysis of 4 studies including a total of 341 patients, standardized mean difference of cardiac troponin I levels were significantly higher in those with severe COVID-19 related illness compared to those with non-severe disease (25.6, 95% CI 6.8-44.5) (45) . Reports have also suggested that acute cardiac injury -which includes not only elevation of cardiac biomarkers to > 99 th percentile of the upper reference limit, but also electrocardiographic and echocardiographic abnormalities -is highly prevalent in patients with COVID-19 and is associated with more severe disease and worse prognosis. Cohort studies from hospitalized patients in China estimate that such injury occurs in 7-17% of hospitalized patients with the disease (1, 6, 19) and is significantly more common in patients admitted to the ICU (22.2% vs. 2.0%, p<0.001) and among those who died (59% vs.\\n 1%, p<0.0001) (6, 8) . However, troponin levels can be exacerbated in patients with renal insufficiency due to delayed excretion, which is common in patients with advanced disease. Given limited high-quality data, and the heterogeneity of definitions across the studies, standardized data collection methods are recommended using the most recent Universal Definition of Myocardial Infarction (MI) (43) .\\n Prior studies in other coronavirus species (MERS-CoV) have demonstrated evidence of acute myocarditis using cardiac magnetic resonance imaging (46) , and myocardial inflammation and damage have been reported with COVID-19 infection. Among 68 deaths in a case series of 150 patients with COVID-19, 7% were attributed to myocarditis with circulatory failure and in 33% of cases which myocarditis may have played a contributing role to the patient's demise (21) . Other reports have described fulminant myocarditis in the setting of high viral load with autopsy findings of inflammatory mononuclear infiltrate in myocardial tissue (26, 47, 48) . Pericardial involvement has not yet been reported but further study is needed. In addition, the extent to which supply and demand mismatch (Type 2 MI) in patients with underlying CVD have contributed to the CV manifestations of the syndrome is uncertain.\\n Case reports of acute coronary syndromes (ACS) (Type 1 MI) in the setting of COVID-19 have yet to be published. Nonetheless, the profound inflammatory response and hemodynamic changes associated with severe disease may confer risk for atherosclerotic plaque rupture in susceptible patients (6) . In this regard, analysis by Kwong (44, 52) .\\n Cardiomyopathy and heart failure. Zhou and colleagues reported that heart failure was observed in 23.0% of patients with COVID-19 presentations (6) . Notably, heart failure was more commonly observed than acute kidney injury in this cohort and was more common in patients who did not survive the hospitalization compared to those who did survive (51.9% vs. 11.7%). Whether heart failure is most commonly due to exacerbation of pre-existing left ventricular dysfunction versus new cardiomyopathy (either due to myocarditis or stress cardiomyopathy) remains unclear (53) . Right heart failure and associated pulmonary hypertension should be also considered, in particular in the context of severe parenchymal lung disease and ARDS.\\n Cardiogenic and mixed shock. The predominant clinical presentation of COVID-19 is acute respiratory illness, which may lead to ARDS manifested as ground-glass opacities on chest imaging (54) and hypoxemia. However, similar features may be seen in the case of de novo or coexisting cardiogenic pulmonary edema. As such, it is important consider cardiogenic or mixed cardiac plus primary pulmonary causes of respiratory manifestations in COVID-19. Historically, right heart catherization was used to determine pulmonary capillary wedge pressure in order to aid in this distinction, although this has been removed from the Berlin criteria used for the diagnosis of ARDS. Rather, the Berlin criteria utilize timing of symptom onset, imaging with bilateral pulmonary opacities, and lack of volume overload to identify patients with ARDS (55) . In many cases, serum brain natriuretic peptide (BNP) and echocardiography can help clarify the diagnosis (56, 57) . However, if these tests are unclear and there remains concern for mixed presentation, pulmonary artery catheterization should be considered in select cases to assess filling considered. The optimal thromboprophylactic regimen for patients hospitalized with COVID-19 related illness is not known. As such, contemporary guideline endorsed strategies should be observed (61) . Given the drug-drug interactions between some antiviral treatments and direct oral anticoagulants, low molecular weight heparins, or unfractionated heparin with or without mechanical prophylaxis are likely to be preferred in acutely ill hospitalized patients.\\n Data regarding antiviral therapies and other treatment strategies, as well as their potential interaction with CV medications and CV toxicities are summarized in Tables 3-5 Methylprednisolone is another drug under investigation that is currently being used to treat severe cases of COVID-19 that are complicated by ARDS (48) . This steroid is known to cause fluid retention, electrolyte derangement, and hypertension as direct CV effects, and also may interact with warfarin via an undescribed mechanism. Clinicians are advised to observe for these drug interactions.\\n Finally, patient debilitation from severe COVID-19 may pose challenges in administering routine CV medications, ranging from antiplatelet therapy to beta-blockers, thus putting patients with or at risk of ischemic heart disease or heart failure at risk of further deterioration of their clinical condition.\\n As the ACE2 receptor is the mechanism of entry for SARS-CoV2, some data suggest that ACE inhibitors (ACEi) and angiotensin receptor blockers (ARB) may upregulate ACE2, thereby increasing susceptibility to the virus ( Figure 1 ) (5) . In contrast other studies show that ACEi/ARB may potentiate the lung protective function of ACE2, which is an angiotensin II inhibitor (80) (81) (82) . Thus, the therapeutic implications for ACEi/ARB therapy during COVID-19 infection is unclear. Overall, there is insufficient data to suggest any mechanistic connections between ACEi/ARB therapy with contracting COVID-19 or with severity illness once infected.\\n Protective equipment for CV health care workers. The Central Illustration demonstrates key considerations for treating patients in the current era of the COVID-19 pandemic. Early reports from the outbreak have suggested that transmission occurs most commonly via respiratory droplets that are produced when an infected individual coughs or sneezes. These droplets can land on exposed mucous membranes or be inhaled into the lungs of those within close proximity and the virus may remain active on surfaces for several days (83) . While the CDC had previously recommended airborne precautions for the care of patients with COVID-19, this recommendation was recently changed such that only patients undergoing aerosol-generating procedures require airborne isolation. Recommendations made by the WHO and CDC for personal protective equipment (PPE) are in agreement that standard, contact precautions with face mask, eye protection, gown, and gloves are necessary (51) .\\n In addition, when performing certain procedures that are aerosol-generating, such as healthcare workers (15) . This fact emphasizes the need for self-protection with PPE before caring for potentially exposed COVID-19 patients, and provides further rationale for delaying elective procedures.\\n In teaching hospitals, it is imperative to minimize exposure among trainees and non-essential staff (e.g.\\n medical students) not only for their own safety and that of their patients, but also for conservation of PPE, and for avoiding the unnecessary increase in the number of asymptomatic vectors. Finally, provider-toprovider transmission is also a major concern, especially in the setting of emergency or suboptimal logistics, or when devices for PPE have become scarce.\\n There are numerous considerations specific to the care of CV patients that should be taken into account in order to minimize risk for COVID-19 transmission to patients and healthcare workers, which are outlined in Table 7 . One important mechanism to help prevent transmission is the use of telemedicine. This technology, already utilized by numerous large health care systems around the world, is ideal in public health crises as it allows for patients to be triaged while minimizing exposure of patients and health care workers to potential infection. Additionally, telemedicine provides an opportunity for specialists that might not otherwise be available to evaluate patients. While there are currently barriers to the widespread implementation of telemedicine such as coordination of testing in patients triaged as high risk, this is a technology that will likely prove important to promote viral containment (86) . Other essential principles are to minimize non-essential/non-urgent in-person provider-patient interactions as much as possible (i.e. social distancing), and limiting elective cardiac catheterization, operating room and echocardiographic procedures. If such procedures are necessary, the number of required personal should be kept to a minimum. (38, 89) . These societies as well as a number of others agree that further data would be vital to inform decisions on adjusting regimens of these agents in the setting of this outbreak (38, (89) (90) (91) (92) . Moving forward, these important CV societies among other large physician groups and health systems will be critical allies to advance the knowledge generation and CV care in patients infected with this virus.\\n package of measures is required for hospital systems to fully prepare for COVID-19 (Table 5) Additionally, repurposing cardiac ICUs as medical ICUs for the care of patients with COVID-19 will likely become necessary, but may limit the quality of specialty care for CV patients. Given the need for ICU beds after cardiac surgery, medical management or percutaneous interventional approaches may need to be preferentially considered for urgent scenarios that cannot wait (e.g. percutaneous coronary intervention rather than coronary artery bypass graft surgery or transcatheter valve solutions rather than surgery) to minimize ICU bed utilization. Furthermore, as aforementioned, appropriate use and careful selection of ECMO-appropriate patients as well as having established ECMO protocols for COVID-19\\n patients are important strategies to consider (58) .\\n Need for education. Information on the most up to date evidence surrounding management and treatment of patients with COVID-19 should be widely disseminated and freely available, and should be provided in illustrative formats (e.g. infographics) that improve public knowledge and understanding. The free flow of communication between healthcare workers and hospitals is paramount to effectively combat the pandemic. The care of patients with COVID-19 will require the expertise of many specialty services including pulmonology/critical care, infectious diseases, cardiology, surgery, pharmacy, and hospital administration among others. Optimal infection control and treatment strategies for COVID-19 should be shared with the entire healthcare community. Accordingly, every effort must be made to provide clear and unambiguous information to patients and decision-makers, countering myths and false news which may generate panic or false optimism. As the evidence base surrounding COVID-19 and its management is evolving on a daily basis, the dissemination of accurate information must occur real-time.\\n Ethical challenges. The unprecedented challenge represented by COVID-19 has brought novel and dramatic ethical dilemmas, ranging from policy issues (e.g. focusing on containment and mitigation vs. herd immunity), as well as clinical dilemmas (e.g. considering all patients alike vs triaging patients according to age, comorbidities and expected prognosis, similar to other catastrophic circumstances).\\n Close interaction between patient advocates, government officials and regulators, as well as physician groups, hospital administrators and other societal leaders will be essential to navigate these ethical challenges.\\n The COVID-19 pandemic has affected hundreds of thousands of patients and poses a major health threat on an international scale. The CV community will play a key role in the management and treatment of patients affected by this disease, and in addition in providing continuity of care to non-infected patients with underlying CVD. In the coming months, efforts towards evaluating new therapies will be crucial to the treatment of this virus, and as this process develops, further appreciation of the intricate interplay between COVID-19, CVD, and the various stakeholders involved including patients, health care workers, and health care systems will be crucial to improving outcomes in at-risk and infected patients. Prospective randomized clinical trials and cohort studies are ongoing and will be important to helping treat patients affected by this virus. ACE2 inhibits production of angiotensin II, which is a potent pro-inflammatory agent in the lung and leads to lung injury. RAAS blockers both directly inhibit production of angiotensin II and may also increase levels of ACE2, thereby indirectly inhibiting angiotensin II (bottom panel). Only a few studies, with single center experience have presented data to date, which limits the generalizability of the findings, and the confidence in the point estimates.\\n This study used multivariable modeling for outcome of death for each CV risk factor for CVD Table 5 summarizes specific recommendations in the setting of medication interactions. ADHF = acute decompensated heart failure; CVA/TIA = cerebrovascular accident/transient ischemic attack. • In, the case of shock, health care workers should continue or discontinue ACEi and ARB therapy on caseby-case basis European Society of Hypertension (38)\\n • As above\\n • Patients with hypertension should continue their home blood pressure medical regimen Canadian Cardiovascular Society (91)\\n • Continuation of ACEi, ARB, and ARNI therapy is strongly recommended in COVID-19 patients \""
      ]
     },
     "execution_count": 992,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corona_df_risk_covid.loc[0,'text_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "risk_covid = corona_df_risk_covid.reset_index()\n",
    "\n",
    "import textwrap\n",
    "import random\n",
    "wrapper = textwrap.TextWrapper(width = 100)\n",
    "summary_examples = corona_df_risk_covid.loc[0,'abstract']\n",
    "\n",
    "print(wrapper.fill(summary_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_df_risk_covid = corona_df_risk_covid.drop_duplicates(['title'])[['doc_id', 'source', 'title', 'abstract', 'text_body',\n",
    "       'index',  'sha', 'source_x', 'doi',\n",
    "       'pmcid', 'pubmed_id', 'license', 'publish_time', 'authors', 'journal',\n",
    "       'Microsoft Academic Paper ID', 'WHO #Covidence', 'has_full_text',\n",
    "       'full_text_file']].reset_index(drop = True)\n",
    "\n",
    "\n",
    "# corona_df_risk_covid.to_csv('/Users/u6066091/Desktop/kaggle/output/corona_challenge/curated/risk_covi.csv')\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'doc_id', 'source', 'title', 'abstract', 'text_body',\n",
       "       'index', 'count_risk', 'sha', 'source_x', 'doi', 'pmcid', 'pubmed_id',\n",
       "       'license', 'publish_time', 'authors', 'journal',\n",
       "       'Microsoft Academic Paper ID', 'WHO #Covidence', 'has_full_text',\n",
       "       'full_text_file'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corona_df_risk_smoke = pd.read_csv('/Users/u6066091/Desktop/kaggle/output/corona_challenge/curated/smoke.csv')\n",
    "corona_df_risk_smoke.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using h_index as a factor for ranking the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_index = pd.read_csv('/Users/u6066091/Downloads/scimagoj_2018.csv',sep = ';')\n",
    "# journal_h_index = list(corona_df_risk_covid[corona_df_risk_covid['journal'].isin(h_index['Title'])]['journal'].unique())\n",
    "df_smoke = corona_df_risk_smoke.join(h_index, lsuffix='journal', rsuffix='Title')\n",
    "df_smoke.columns = ['Unnamed: 0', 'doc_id', 'source', 'title', 'abstract', 'text_body',\n",
    "       'index', 'count_risk', 'sha', 'source_x', 'doi', 'pmcid', 'pubmed_id',\n",
    "       'license', 'publish_time', 'authors', 'journal',\n",
    "       'Microsoft Academic Paper ID', 'WHO #Covidence', 'has_full_text',\n",
    "       'full_text_file', 'Rank', 'Sourceid', 'Title', 'Type', 'Issn', 'SJR',\n",
    "       'SJR Best Quartile', 'H_index', 'Total Docs. (2018)',\n",
    "       'Total Docs. (3years)', 'Total Refs.', 'Total Cites (3years)',\n",
    "       'Citable Docs. (3years)', 'Cites / Doc. (2years)', 'Ref. / Doc.',\n",
    "       'Country', 'Publisher', 'Coverage', 'Categories']\n",
    "\n",
    "df_smoke = df_smoke[['doc_id', 'source', 'title', 'abstract', 'text_body',\n",
    "       'index', 'count_risk', 'sha', 'source_x', 'doi', 'pmcid', 'pubmed_id',\n",
    "       'license', 'publish_time', 'authors', 'journal',\n",
    "       'Microsoft Academic Paper ID', 'WHO #Covidence', 'has_full_text',\n",
    "       'full_text_file', 'Rank', 'Sourceid','Type', 'Issn', 'SJR',\n",
    "       'SJR Best Quartile', 'H_index', 'Total Docs. (2018)',\n",
    "       'Total Docs. (3years)', 'Total Refs.', 'Total Cites (3years)',\n",
    "       'Citable Docs. (3years)', 'Cites / Doc. (2years)', 'Ref. / Doc.',\n",
    "       'Country', 'Publisher', 'Coverage', 'Categories']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "risk_count = [str(i).lower().count('risk')/len(str(i).lower()) for i in df_smoke_sel['text_body']]\n",
    "covid_count = [str(i).lower().count('covi')*10/len(str(i).lower()) for i in df_smoke_sel['text_body']]\n",
    "smok_count = [str(i).lower().count('smok')/len(str(i).lower()) for i in df_smoke_sel['text_body']]\n",
    "pulm_count = [str(i).lower().count('pulm')/len(str(i).lower()) for i in df_smoke_sel['text_body']]\n",
    "\n",
    "normalized_count = np.sum([risk_count, covid_count,smok_count, pulm_count] , axis = 0)\n",
    "rank = np.array(normalized_count)*100 + np.mean(df_smoke_sel['H_index'])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating SciSpacy for sentence similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9bdf96e896214215a944b4f73a3173dd-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sentence.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9bdf96e896214215a944b4f73a3173dd-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9bdf96e896214215a944b4f73a3173dd-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9bdf96e896214215a944b4f73a3173dd-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9bdf96e896214215a944b4f73a3173dd-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9bdf96e896214215a944b4f73a3173dd-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9bdf96e896214215a944b4f73a3173dd-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "displacy.serve(doc, style=\"dep\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_lg-0.2.4.tar.gz\n",
      "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_lg-0.2.4.tar.gz (500.6 MB)\n",
      "Requirement already satisfied (use --upgrade to upgrade): en-core-sci-lg==0.2.4 from https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_lg-0.2.4.tar.gz in /opt/anaconda3/lib/python3.7/site-packages\n",
      "Requirement already satisfied: spacy>=2.2.1 in /opt/anaconda3/lib/python3.7/site-packages (from en-core-sci-lg==0.2.4) (2.2.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (46.1.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (2.22.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (4.42.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (7.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en-core-sci-lg==0.2.4) (1.18.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.1->en-core-sci-lg==0.2.4) (1.5.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en-core-sci-lg==0.2.4) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en-core-sci-lg==0.2.4) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en-core-sci-lg==0.2.4) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en-core-sci-lg==0.2.4) (2019.11.28)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.1->en-core-sci-lg==0.2.4) (2.2.0)\n",
      "Building wheels for collected packages: en-core-sci-lg\n",
      "  Building wheel for en-core-sci-lg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-core-sci-lg: filename=en_core_sci_lg-0.2.4-py3-none-any.whl size=501343161 sha256=121d30d907e6bf97109ae5d6e954082340cf664099e756503337e2b2d4ae4fa0\n",
      "  Stored in directory: /Users/u6066091/Library/Caches/pip/wheels/06/a3/b5/bacce7d280488beaf177c3eadbe9f440244201544a0461f6f3\n",
      "Successfully built en-core-sci-lg\n",
      "Requirement already satisfied: en_core_sci_lg in /opt/anaconda3/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied: spacy>=2.2.1 in /opt/anaconda3/lib/python3.7/site-packages (from en_core_sci_lg) (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (1.18.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (4.42.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (1.0.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (7.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (3.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (1.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (46.1.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.1->en_core_sci_lg) (0.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_core_sci_lg) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_core_sci_lg) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_core_sci_lg) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en_core_sci_lg) (1.25.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.1->en_core_sci_lg) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.1->en_core_sci_lg) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_lg-0.2.4.tar.gz\n",
    "!pip install en_core_sci_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scispacy\n",
    "import spacy\n",
    "import en_core_sci_lg   #The model we are going to use\n",
    "from spacy import displacy\n",
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "from scispacy.umls_linking import UmlsEntityLinker\n",
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "from scispacy.umls_linking import UmlsEntityLinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abbreviation \t Definition\n"
     ]
    }
   ],
   "source": [
    "nlp = en_core_sci_lg.load()\n",
    "# nlp = spacy.load(\"en_core_sci_sm\") \n",
    "text = 'Myeloid derived suppressor cells (MDSC) are immature myeloid cells with immunosuppressive activity.'\n",
    "#           They accumulate in tumor-bearing mice and humans \n",
    "#           with different types of cancer, including hepatocellular \n",
    "#           carcinoma (HCC).'\n",
    "abbreviation_pipe = AbbreviationDetector(nlp)\n",
    "nlp.add_pipe(abbreviation_pipe)\n",
    "#Print the Abbreviation and it's definition\n",
    "print(\"Abbreviation\", \"\\t\", \"Definition\")\n",
    "for abrv in doc._.abbreviations:\n",
    "      print(f\"{abrv} \\t ({abrv.start}, {abrv.end}) {abrv._.long_form}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9909571702198852"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "token1 = nlp('Myeloid derived suppressor cells (MDSC) are immature myeloid cells with immunosuppressive activity.')\n",
    "token2 = nlp('derived suppressor cells (MDSC) are immature myeloid cells with immunosuppressive activity.')\n",
    "\n",
    "token2.similarity(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "annotate = pd.read_excel('/Users/u6066091/Desktop/kaggle/annotated/smoke_risk_factor.xlsx')\n",
    "annotate.columns = ['Text', 'Label']\n",
    "annotate['Text'] = annotate['Text'].str.replace('\\xa0',' ')\n",
    "nlp = en_core_sci_lg.load()\n",
    "# nlp = spacy.load(\"en_core_sci_lg\")\n",
    "\n",
    "article1 = pd.read_csv('/Users/u6066091/Desktop/kaggle/output/corona_challenge/curated/keshav/risk_covid_summary.csv')\n",
    "sim_list = []\n",
    "sim_num = [] \n",
    "# jj = article1['summary'][0][1]\n",
    "for jj in article1['summary']:\n",
    "    for j in jj.split('.'):\n",
    "        sim = [nlp(i).similarity(nlp(j)) for i in annotate['Text']]\n",
    "        sim_list.append([j,sim.index(max(sim))])\n",
    "        sim_num.append(max(sim))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In December 2019, an outbreak of Corona Virus Disease 2019 (COVID-19) caused by a novel coronavirus (severe acute respiratory syndrome coronavirus 2, SARS-CoV-2) began in Wuhan (Hubei, China) and spread rapidly (1) . Without efficient medicine, early detection and isolation becomes essential against novel coronavirus. Pulmonary edema caused by heart failure can be appeared as exudative disease in CT scanning, which is, sometimes, difficult to be distinguished with other exudative disease in clinical practice. Patients with negative CT findings and less than 18-years old were excluded. CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity. is the (which was not peer-reviewed) The copyright holder for this preprint . All the COVID-19 patients were diagnosed in fever clinics and then transferred to the designated hospital in Changsha, China. Clinical records, laboratory findings, and chest CT scans for all patients were obtained at initial medical contact. Throat-swab specimens from the upper respiratory tract were obtained. Statistical analysis was done with SPSS, version 25.0. Categorical variables were expressed as number (%). White blood cell and neutrophil count was higher in heart failure group compared with that in COVID-19 group [7.32 (100) <0.001 Values are median (interquartile range), n (%), or mean ± SD. The comparison of imaging features was concluded in Table 2 . Compared with patients with COVID-19, 11 patients in 12 had GGO in heart failure group, and there was no statistical difference between two groups (92% vs. 83%, p=0.537). Besides, more fibrous lesions were found in COVID-19 group although there was no statistical difference (25% vs. 0%, . He was diagnosed with coronary artery disease in last year and was stented in Left anterior descending artery. We found that GGO and septal thickening were all common lesions in both diseases. Significant differences exist in the distribution type, lesion morphology, upper small pulmonary vein enlargement, fissural thickening, peribronchovascular thickening, subpleural effusion and cardiac enlargement. Up to present, China has updated to the 7 th edition of the diagnosis for suspected patients. In this study, 4 patients in 12 have respiratory symptoms. Besides, nearly half of COVID-19 patients may not have fever at admission(6) and the lymphocyte count in patients with heart failure can also be decreased. In this study, we found that there are some similarities in imaging features for patients with heart failure and COVID-19 pneumonia. of the two kinds of diseases were significantly different. Heart failure were more likely to have a central and gravity associated gradient distribution, while COVID-19 usually have more peripheral distribution. While COVID-19 usually affected the smaller septum. COVID-19 usually progresses with different imaging features at different stages last for about 2-3 weeks (7). At first GGO is the predominant feature and gradually spread and consolidated, at last stage, the consolidation will be absorbed. This study was just focus on the initial medical contact, and the CT imaging showed here were almost belong to the early stage. So predominated GGO and some consolidation were most popular in COVID-19. Recently, fibromyxoid exudation has been found in the lung tissue from patient obtained at autopsy (10) , which is absent in heart failure. In this study, the leukocyte and neutrophil count of patients with heart failure was significantly higher than that of covid-19 patients, which may be attributed to the inflammatory state in vivo induced by heart failure or acute myocardial infarction (11, 12) . There are several limitations of this study. https://doi.org/10.1101/2020.03.04.20031047 doi: medRxiv preprint features of COVID-19 and heart failure. Although both diseases can have similar GGO and septal thickening, rounded morphology, peripheral distribution and fibrous lesion were relatively specific in COVID-19. E, Multiple disease mixed with GGO and consolidation in bilateral lungs.'"
      ]
     },
     "execution_count": 1143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article1['summary'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphShow():\n",
    "    \"\"\"\"Create demo page\"\"\"\n",
    "    def __init__(self):\n",
    "        self.base = '''\n",
    "    <html>\n",
    "    <head>\n",
    "      <script type=\"text/javascript\" src=\"VIS/dist/vis.js\"></script>\n",
    "      <link href=\"VIS/dist/vis.css\" rel=\"stylesheet\" type=\"text/css\">\n",
    "      <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n",
    "    </head>\n",
    "    <body>\n",
    "    <div id=\"VIS_draw\"></div>\n",
    "    <script type=\"text/javascript\">\n",
    "      var nodes = data_nodes;\n",
    "      var edges = data_edges;\n",
    "      var container = document.getElementById(\"VIS_draw\");\n",
    "      var data = {\n",
    "        nodes: nodes,\n",
    "        edges: edges\n",
    "      };\n",
    "      var options = {\n",
    "          nodes: {\n",
    "              shape: 'circle',\n",
    "              size: 15,\n",
    "              font: {\n",
    "                  size: 15\n",
    "              }\n",
    "          },\n",
    "          edges: {\n",
    "              font: {\n",
    "                  size: 10,\n",
    "                  align: 'center'\n",
    "              },\n",
    "              color: 'red',\n",
    "              arrows: {\n",
    "                  to: {enabled: true, scaleFactor: 1.2}\n",
    "              },\n",
    "              smooth: {enabled: true}\n",
    "          },\n",
    "          physics: {\n",
    "              enabled: true\n",
    "          }\n",
    "      };\n",
    "      var network = new vis.Network(container, data, options);\n",
    "    </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    '''\n",
    "    \n",
    "\n",
    "    def create_page(self, events):\n",
    "        \"\"\"Read data\"\"\"\n",
    "        nodes = []\n",
    "        for event in events:\n",
    "            nodes.append(event[0])\n",
    "            nodes.append(event[1])\n",
    "        node_dict = {node: index for index, node in enumerate(nodes)}\n",
    "\n",
    "        data_nodes = []\n",
    "        data_edges = []\n",
    "        for node, id in node_dict.items():\n",
    "            data = {}\n",
    "            data[\"group\"] = 'Event'\n",
    "            data[\"id\"] = id\n",
    "            data[\"label\"] = node\n",
    "            data_nodes.append(data)\n",
    "\n",
    "        for edge in events:\n",
    "            data = {}\n",
    "            data['from'] = node_dict.get(edge[0])\n",
    "            data['label'] = ''\n",
    "            data['to'] = node_dict.get(edge[1])\n",
    "            data_edges.append(data)\n",
    "\n",
    "        self.create_html(data_nodes, data_edges)\n",
    "        return\n",
    "\n",
    "    def create_html(self, data_nodes, data_edges):\n",
    "        \"\"\"Generate html file\"\"\"\n",
    "        f = open('graph_show.html', 'w+')\n",
    "        html = self.base.replace('data_nodes', str(data_nodes)).replace('data_edges', str(data_edges))\n",
    "        f.write(html)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !pip install scispacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class TextrankGraph:\n",
    "    '''textrank graph'''\n",
    "    def __init__(self):\n",
    "        self.graph = defaultdict(list)\n",
    "        self.d = 0.85 # damping coefficient, usually is .85\n",
    "        self.min_diff = 1e-5 # convergence threshold\n",
    "        self.steps = 1000 # iteration steps\n",
    "\n",
    "    def addEdge(self, start, end, weight):\n",
    "        \"\"\"Add edge between node\"\"\"\n",
    "        self.graph[start].append((start, end, weight))\n",
    "        self.graph[end].append((end, start, weight))\n",
    "\n",
    "    def rank(self):\n",
    "        \"\"\"Rank all nodes\"\"\"\n",
    "        weight_deafault = 1.0 / (len(self.graph) or 1.0) # initialize weight\n",
    "        nodeweight_dict = defaultdict(float) # store weight of node\n",
    "        outsum_node_dict = defaultdict(float) # store wegiht of out nodes\n",
    "        for node, out_edge in self.graph.items(): # initilize nodes weight by edges\n",
    "            # node: was\n",
    "            # out_edge: [('was', 'prison', 1), ('was', 'wrong', 1), ('was', 'bad', 1)]\n",
    "            nodeweight_dict[node] = weight_deafault\n",
    "            outsum_node_dict[node] = sum((edge[2] for edge in out_edge), 0.0) # if no out edge, set weight 0\n",
    "        \n",
    "        sorted_keys = sorted(self.graph.keys()) # save node name as a list for iteration\n",
    "        step_dict = [0]\n",
    "        for step in range(1, self.steps):\n",
    "            for node in sorted_keys:\n",
    "                s = 0\n",
    "                # Node's weight calculation: \n",
    "                # (edge_weight/ node's number of out link)*node_weight[edge_node]\n",
    "                for e in self.graph[node]:\n",
    "                    s += e[2] / outsum_node_dict[e[1]] * nodeweight_dict[e[1]]\n",
    "                # Update calculation: (1-d) + d*s\n",
    "                nodeweight_dict[node] = (1 - self.d) + self.d * s\n",
    "            step_dict.append(sum(nodeweight_dict.values()))\n",
    "\n",
    "            if abs(step_dict[step] - step_dict[step - 1]) <= self.min_diff:\n",
    "                break\n",
    "\n",
    "        # min-max scale to make result in range to [0 - 1]\n",
    "        min_rank, max_rank = 0, 0 # initilize max and min wegiht value\n",
    "        for w in nodeweight_dict.values():\n",
    "            if w < min_rank:\n",
    "                min_rank = w\n",
    "            if w > max_rank:\n",
    "                max_rank = w\n",
    "\n",
    "        for n, w in nodeweight_dict.items():\n",
    "            nodeweight_dict[n] = (w - min_rank/10.0) / (max_rank - min_rank/10.0)\n",
    "\n",
    "        return nodeweight_dict\n",
    "\n",
    "\n",
    "class TextRank:\n",
    "    \"\"\"Extract keywords based on textrank graph algorithm\"\"\"\n",
    "    def __init__(self):\n",
    "        self.candi_pos = ['NOUN', 'PROPN', 'VERB'] # 名词，专有名词，动词\n",
    "        self.stop_pos = ['NUM', 'ADV'] # 数字（没有时间名词，就用数字代表了），副词\n",
    "        self.span = 5\n",
    "\n",
    "    def extract_keywords(self, word_list, num_keywords):\n",
    "        g = TextrankGraph()\n",
    "        cm = defaultdict(int)\n",
    "        for i, word in enumerate(word_list): # word_list = [['previous', 'ADJ'], ['rumor', 'NOUN']]\n",
    "            if word[1] in self.candi_pos and len(word[0]) > 1: # word = ['previous', 'ADJ']\n",
    "                for j in range(i + 1, i + self.span):\n",
    "                    if j >= len(word_list):\n",
    "                        break\n",
    "                    if word_list[j][1] not in self.candi_pos or word_list[j][1] in self.stop_pos or len(word_list[j][0]) < 2:\n",
    "                        continue\n",
    "                    pair = tuple((word[0], word_list[j][0]))\n",
    "                    cm[(pair)] +=  1\n",
    "\n",
    "        # cm = {('was', 'prison'): 1, ('become', 'prison'): 1}\n",
    "        for terms, w in cm.items():\n",
    "            g.addEdge(terms[0], terms[1], w)\n",
    "        nodes_rank = g.rank()\n",
    "        nodes_rank = sorted(nodes_rank.items(), key=lambda asd:asd[1], reverse=True)\n",
    "\n",
    "        return nodes_rank[:num_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import scispacy\n",
    "# import GraphShow\n",
    "# from textrank import TextRank\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "class NewsMining():\n",
    "    \"\"\"News Mining\"\"\"\n",
    "    def __init__(self):\n",
    "        self.textranker = TextRank()\n",
    "        self.ners = ['PERSON', 'ORG', 'GPE']\n",
    "        self.ner_dict = {\n",
    "            'PERSON': 'Person',  # People, including fictional\n",
    "            'ORG': 'Organization',  # Companies, agencies, institutions, etc.\n",
    "            'GPE': 'Location',  # Countries, cities, states.\n",
    "        }\n",
    "        # dependency markers for subjects\n",
    "        self.SUBJECTS = {\"nsubj\", \"nsubjpass\",\n",
    "                         \"csubj\", \"csubjpass\", \"agent\", \"expl\"}\n",
    "        # dependency markers for objects\n",
    "        self.OBJECTS = {\"dobj\", \"dative\", \"attr\", \"oprd\"}\n",
    "\n",
    "        self.graph_shower = GraphShow()\n",
    "\n",
    "    def clean_spaces(self, s):\n",
    "        s = s.replace('\\r', '')\n",
    "        s = s.replace('\\t', ' ')\n",
    "        s = s.replace('\\n', ' ')\n",
    "        return s\n",
    "\n",
    "    def remove_noisy(self, content):\n",
    "        \"\"\"Remove brackets\"\"\"\n",
    "        p1 = re.compile(r'（[^）]*）')\n",
    "        p2 = re.compile(r'\\([^\\)]*\\)')\n",
    "        return p2.sub('', p1.sub('', content))\n",
    "\n",
    "    def collect_ners(self, ents):\n",
    "        \"\"\"Collect token only with PERSON, ORG, GPE\"\"\"\n",
    "        collected_ners = []\n",
    "        for token in ents:\n",
    "            if token.label_ in self.ners:\n",
    "                collected_ners.append(token.text + '/' + token.label_)\n",
    "        return collected_ners\n",
    "\n",
    "    def conll_syntax(self, sent):\n",
    "        \"\"\"Convert one sentence to conll format.\"\"\"\n",
    "\n",
    "        tuples = list()\n",
    "        for word in sent:\n",
    "            if word.head is word:\n",
    "                head_idx = 0\n",
    "            else:\n",
    "                head_idx = word.head.i + 1\n",
    "            tuples.append([word.i + 1,  # Current word index, begin with 1\n",
    "                           word.text,  # Word\n",
    "                           word.lemma_,  # Lemma\n",
    "                           word.pos_,  # Coarse-grained tag\n",
    "                           word.tag_,  # Fine-grained tag\n",
    "                           '_',\n",
    "                           head_idx,  # Head of current  Index\n",
    "                           word.dep_,  # Relation\n",
    "                           '_', '_'])\n",
    "        return tuples\n",
    "\n",
    "    def syntax_parse(self, sent):\n",
    "        \"\"\"Convert one sentence to conll format.\"\"\"\n",
    "        tuples = list()\n",
    "        for word in sent:\n",
    "            if word.head is word:\n",
    "                head_idx = 0\n",
    "            else:\n",
    "                head_idx = word.head.i + 1\n",
    "            tuples.append([word.i + 1,  # Current word index, begin with 1\n",
    "                           word.text,  # Word\n",
    "                           word.pos_,  # Coarse-grained tag\n",
    "                           word.head,\n",
    "                           head_idx,  # Head of current  Index\n",
    "                           word.dep_,  # Relation\n",
    "                           ])\n",
    "        return tuples\n",
    "\n",
    "    def build_parse_chile_dict(self, sent, tuples):\n",
    "        child_dict_list = list()\n",
    "        for word in sent:\n",
    "            child_dict = dict()\n",
    "            for arc in tuples:\n",
    "                if arc[3] == word:\n",
    "                    if arc[-1] in child_dict:\n",
    "                        child_dict[arc[-1]].append(arc)\n",
    "                    else:\n",
    "                        child_dict[arc[-1]] = []\n",
    "                        child_dict[arc[-1]].append(arc)\n",
    "            child_dict_list.append([word, word.pos_, word.i, child_dict])\n",
    "        return child_dict_list\n",
    "\n",
    "    def complete_VOB(self, verb, child_dict_list):\n",
    "        '''Find VOB by SBV'''\n",
    "        for child in child_dict_list:\n",
    "            word = child[0]\n",
    "            # child_dict: {'dobj': [[7, 'startup', 'NOUN', buying, 5, 'dobj']], 'prep': [[8, 'for', 'ADP', buying, 5, 'prep']]}\n",
    "            child_dict = child[3]\n",
    "            if word == verb:\n",
    "                for object_type in self.OBJECTS:  # object_type: 'dobj'\n",
    "                    if object_type not in child_dict:\n",
    "                        continue\n",
    "                    # [7, 'startup', 'NOUN', buying, 5, 'dobj']\n",
    "                    vob = child_dict[object_type][0]\n",
    "                    obj = vob[1]  # 'startup'\n",
    "                    return obj\n",
    "        return ''\n",
    "\n",
    "    def extract_triples(self, sent):\n",
    "        svo = []\n",
    "        tuples = self.syntax_parse(sent)\n",
    "        child_dict_list = self.build_parse_chile_dict(sent, tuples)\n",
    "        for tuple in tuples:\n",
    "            rel = tuple[-1]\n",
    "            if rel in self.SUBJECTS:\n",
    "                sub_wd = tuple[1]\n",
    "                verb_wd = tuple[3]\n",
    "                obj = self.complete_VOB(verb_wd, child_dict_list)\n",
    "                subj = sub_wd\n",
    "                verb = verb_wd.text\n",
    "                if not obj:\n",
    "                    svo.append([subj, verb])\n",
    "                else:\n",
    "                    svo.append([subj, verb+' '+obj])\n",
    "        return svo\n",
    "\n",
    "    def extract_keywords(self, words_postags):\n",
    "        return self.textranker.extract_keywords(words_postags, 10)\n",
    "\n",
    "    def collect_coexist(self, ner_sents, ners):\n",
    "        \"\"\"Construct NER co-occurrence matrices\"\"\"\n",
    "        co_list = []\n",
    "        for words in ner_sents:\n",
    "            co_ners = set(ners).intersection(set(words))\n",
    "            co_info = self.combination(list(co_ners))\n",
    "            co_list += co_info\n",
    "        if not co_list:\n",
    "            return []\n",
    "        return {i[0]: i[1] for i in Counter(co_list).most_common()}\n",
    "\n",
    "    def combination(self, a):\n",
    "        '''list all combination'''\n",
    "        combines = []\n",
    "        if len(a) == 0:\n",
    "            return []\n",
    "        for i in a:\n",
    "            for j in a:\n",
    "                if i == j:\n",
    "                    continue\n",
    "                combines.append('@'.join([i, j]))\n",
    "        return combines\n",
    "\n",
    "    def main(self, content):\n",
    "        '''Main function'''\n",
    "        if not content:\n",
    "            return []\n",
    "\n",
    "        words_postags = []  # token and its POS tag\n",
    "        ner_sents = []      # store sentences which contain NER entity\n",
    "        ners = []           # store all NER entity from whole article\n",
    "        triples = []        # store subject verb object\n",
    "        events = []         # store events\n",
    "\n",
    "        # 01 remove linebreaks and brackets\n",
    "        content = self.remove_noisy(content)\n",
    "        content = self.clean_spaces(content)\n",
    "\n",
    "        # 02 split to sentences\n",
    "        doc = nlp(content)\n",
    "\n",
    "        for i, sent in enumerate(doc.sents):\n",
    "            words_postags = [[token.text, token.pos_] for token in sent]\n",
    "            words = [token.text for token in sent]\n",
    "            postags = [token.pos_ for token in sent]\n",
    "            ents = nlp(sent.text).ents  # NER detection\n",
    "            collected_ners = self.collect_ners(ents)\n",
    "\n",
    "            if collected_ners:  # only extract triples when the sentence contains 'PERSON', 'ORG', 'GPE'\n",
    "                triple = self.extract_triples(sent)\n",
    "                if not triple:\n",
    "                    continue\n",
    "                triples += triple\n",
    "                ners += collected_ners\n",
    "                ner_sents.append(\n",
    "                    [token.text + '/' + token.label_ for token in sent.ents])\n",
    "\n",
    "        # 03 get keywords\n",
    "        keywords = [i[0] for i in self.extract_keywords(words_postags)]\n",
    "        for keyword in keywords:\n",
    "            name = keyword\n",
    "            cate = 'keyword'\n",
    "            events.append([name, cate])\n",
    "\n",
    "        # 04 add triples to event only the word in keyword\n",
    "        for t in triples:\n",
    "            if (t[0] in keywords or t[1] in keywords) and len(t[0]) > 1 and len(t[1]) > 1:\n",
    "                events.append([t[0], t[1]])\n",
    "\n",
    "        # 05 get word frequency and add to events\n",
    "        word_dict = [i for i in Counter([i[0] for i in words_postags if i[1] in [\n",
    "                                        'NOUN', 'PROPN', 'VERB'] and len(i[0]) > 1]).most_common()][:10]\n",
    "        for wd in word_dict:\n",
    "            name = wd[0]\n",
    "            cate = 'frequency'\n",
    "            events.append([name, cate])\n",
    "\n",
    "        # 06 get NER from whole article\n",
    "        ner_dict = {i[0]: i[1] for i in Counter(ners).most_common(20)}\n",
    "        for ner in ner_dict:\n",
    "            name = ner.split('/')[0]  # Jessica Miller\n",
    "            cate = self.ner_dict[ner.split('/')[1]]  # PERSON\n",
    "            events.append([name, cate])\n",
    "\n",
    "        # 07 get all NER entity co-occurrence information\n",
    "        # here ner_dict is from above 06\n",
    "        co_dict = self.collect_coexist(ner_sents, list(ner_dict.keys()))\n",
    "        co_events = [[i.split('@')[0].split(\n",
    "            '/')[0], i.split('@')[1].split('/')[0]] for i in co_dict]\n",
    "        events += co_events\n",
    "\n",
    "        # 08 show event graph\n",
    "        self.graph_shower.create_page(events)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import spacy\n",
    "# from graph_show import GraphShow\n",
    "# from textrank import TextRank\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "class NewsMining():\n",
    "    \"\"\"News Mining\"\"\"\n",
    "    def __init__(self):\n",
    "        self.textranker = TextRank()\n",
    "        self.ners = ['PERSON', 'ORG', 'GPE']\n",
    "        self.ner_dict = {\n",
    "            'PERSON': 'Person',  # People, including fictional\n",
    "            'ORG': 'Organization',  # Companies, agencies, institutions, etc.\n",
    "            'GPE': 'Location',  # Countries, cities, states.\n",
    "        }\n",
    "        # dependency markers for subjects\n",
    "        self.SUBJECTS = {\"nsubj\", \"nsubjpass\",\n",
    "                         \"csubj\", \"csubjpass\", \"agent\", \"expl\"}\n",
    "        # dependency markers for objects\n",
    "        self.OBJECTS = {\"dobj\", \"dative\", \"attr\", \"oprd\"}\n",
    "\n",
    "        self.graph_shower = GraphShow()\n",
    "\n",
    "    def clean_spaces(self, s):\n",
    "        s = s.replace('\\r', '')\n",
    "        s = s.replace('\\t', ' ')\n",
    "        s = s.replace('\\n', ' ')\n",
    "        return s\n",
    "\n",
    "    def remove_noisy(self, content):\n",
    "        \"\"\"Remove brackets\"\"\"\n",
    "        p1 = re.compile(r'（[^）]*）')\n",
    "        p2 = re.compile(r'\\([^\\)]*\\)')\n",
    "        return p2.sub('', p1.sub('', content))\n",
    "\n",
    "    def collect_ners(self, ents):\n",
    "        \"\"\"Collect token only with PERSON, ORG, GPE\"\"\"\n",
    "        collected_ners = []\n",
    "        for token in ents:\n",
    "            if token.label_ in self.ners:\n",
    "                collected_ners.append(token.text + '/' + token.label_)\n",
    "        return collected_ners\n",
    "\n",
    "    def conll_syntax(self, sent):\n",
    "        \"\"\"Convert one sentence to conll format.\"\"\"\n",
    "\n",
    "        tuples = list()\n",
    "        for word in sent:\n",
    "            if word.head is word:\n",
    "                head_idx = 0\n",
    "            else:\n",
    "                head_idx = word.head.i + 1\n",
    "            tuples.append([word.i + 1,  # Current word index, begin with 1\n",
    "                           word.text,  # Word\n",
    "                           word.lemma_,  # Lemma\n",
    "                           word.pos_,  # Coarse-grained tag\n",
    "                           word.tag_,  # Fine-grained tag\n",
    "                           '_',\n",
    "                           head_idx,  # Head of current  Index\n",
    "                           word.dep_,  # Relation\n",
    "                           '_', '_'])\n",
    "        return tuples\n",
    "\n",
    "    def syntax_parse(self, sent):\n",
    "        \"\"\"Convert one sentence to conll format.\"\"\"\n",
    "        tuples = list()\n",
    "        for word in sent:\n",
    "            if word.head is word:\n",
    "                head_idx = 0\n",
    "            else:\n",
    "                head_idx = word.head.i + 1\n",
    "            tuples.append([word.i + 1,  # Current word index, begin with 1\n",
    "                           word.text,  # Word\n",
    "                           word.pos_,  # Coarse-grained tag\n",
    "                           word.head,\n",
    "                           head_idx,  # Head of current  Index\n",
    "                           word.dep_,  # Relation\n",
    "                           ])\n",
    "        return tuples\n",
    "\n",
    "    def build_parse_chile_dict(self, sent, tuples):\n",
    "        child_dict_list = list()\n",
    "        for word in sent:\n",
    "            child_dict = dict()\n",
    "            for arc in tuples:\n",
    "                if arc[3] == word:\n",
    "                    if arc[-1] in child_dict:\n",
    "                        child_dict[arc[-1]].append(arc)\n",
    "                    else:\n",
    "                        child_dict[arc[-1]] = []\n",
    "                        child_dict[arc[-1]].append(arc)\n",
    "            child_dict_list.append([word, word.pos_, word.i, child_dict])\n",
    "        return child_dict_list\n",
    "\n",
    "    def complete_VOB(self, verb, child_dict_list):\n",
    "        '''Find VOB by SBV'''\n",
    "        for child in child_dict_list:\n",
    "            word = child[0]\n",
    "            # child_dict: {'dobj': [[7, 'startup', 'NOUN', buying, 5, 'dobj']], 'prep': [[8, 'for', 'ADP', buying, 5, 'prep']]}\n",
    "            child_dict = child[3]\n",
    "            if word == verb:\n",
    "                for object_type in self.OBJECTS:  # object_type: 'dobj'\n",
    "                    if object_type not in child_dict:\n",
    "                        continue\n",
    "                    # [7, 'startup', 'NOUN', buying, 5, 'dobj']\n",
    "                    vob = child_dict[object_type][0]\n",
    "                    obj = vob[1]  # 'startup'\n",
    "                    return obj\n",
    "        return ''\n",
    "\n",
    "    def extract_triples(self, sent):\n",
    "        svo = []\n",
    "        tuples = self.syntax_parse(sent)\n",
    "        child_dict_list = self.build_parse_chile_dict(sent, tuples)\n",
    "        for tuple in tuples:\n",
    "            rel = tuple[-1]\n",
    "            if rel in self.SUBJECTS:\n",
    "                sub_wd = tuple[1]\n",
    "                verb_wd = tuple[3]\n",
    "                obj = self.complete_VOB(verb_wd, child_dict_list)\n",
    "                subj = sub_wd\n",
    "                verb = verb_wd.text\n",
    "                if not obj:\n",
    "                    svo.append([subj, verb])\n",
    "                else:\n",
    "                    svo.append([subj, verb+' '+obj])\n",
    "        return svo\n",
    "\n",
    "    def extract_keywords(self, words_postags):\n",
    "        return self.textranker.extract_keywords(words_postags, 10)\n",
    "\n",
    "    def collect_coexist(self, ner_sents, ners):\n",
    "        \"\"\"Construct NER co-occurrence matrices\"\"\"\n",
    "        co_list = []\n",
    "        for words in ner_sents:\n",
    "            co_ners = set(ners).intersection(set(words))\n",
    "            co_info = self.combination(list(co_ners))\n",
    "            co_list += co_info\n",
    "        if not co_list:\n",
    "            return []\n",
    "        return {i[0]: i[1] for i in Counter(co_list).most_common()}\n",
    "\n",
    "    def combination(self, a):\n",
    "        '''list all combination'''\n",
    "        combines = []\n",
    "        if len(a) == 0:\n",
    "            return []\n",
    "        for i in a:\n",
    "            for j in a:\n",
    "                if i == j:\n",
    "                    continue\n",
    "                combines.append('@'.join([i, j]))\n",
    "        return combines\n",
    "\n",
    "    def main(self, content):\n",
    "        '''Main function'''\n",
    "        if not content:\n",
    "            return []\n",
    "\n",
    "        words_postags = []  # token and its POS tag\n",
    "        ner_sents = []      # store sentences which contain NER entity\n",
    "        ners = []           # store all NER entity from whole article\n",
    "        triples = []        # store subject verb object\n",
    "        events = []         # store events\n",
    "\n",
    "        # 01 remove linebreaks and brackets\n",
    "        content = self.remove_noisy(content)\n",
    "        content = self.clean_spaces(content)\n",
    "\n",
    "        # 02 split to sentences\n",
    "        doc = nlp(content)\n",
    "\n",
    "        for i, sent in enumerate(doc.sents):\n",
    "            words_postags = [[token.text, token.pos_] for token in sent]\n",
    "            words = [token.text for token in sent]\n",
    "            postags = [token.pos_ for token in sent]\n",
    "            ents = nlp(sent.text).ents  # NER detection\n",
    "            collected_ners = self.collect_ners(ents)\n",
    "\n",
    "            if collected_ners:  # only extract triples when the sentence contains 'PERSON', 'ORG', 'GPE'\n",
    "                triple = self.extract_triples(sent)\n",
    "                if not triple:\n",
    "                    continue\n",
    "                triples += triple\n",
    "                ners += collected_ners\n",
    "                ner_sents.append(\n",
    "                    [token.text + '/' + token.label_ for token in sent.ents])\n",
    "\n",
    "        # 03 get keywords\n",
    "        keywords = [i[0] for i in self.extract_keywords(words_postags)]\n",
    "        for keyword in keywords:\n",
    "            name = keyword\n",
    "            cate = 'keyword'\n",
    "            events.append([name, cate])\n",
    "\n",
    "        # 04 add triples to event only the word in keyword\n",
    "        for t in triples:\n",
    "            if (t[0] in keywords or t[1] in keywords) and len(t[0]) > 1 and len(t[1]) > 1:\n",
    "                events.append([t[0], t[1]])\n",
    "\n",
    "        # 05 get word frequency and add to events\n",
    "        word_dict = [i for i in Counter([i[0] for i in words_postags if i[1] in [\n",
    "                                        'NOUN', 'PROPN', 'VERB'] and len(i[0]) > 1]).most_common()][:10]\n",
    "        for wd in word_dict:\n",
    "            name = wd[0]\n",
    "            cate = 'frequency'\n",
    "            events.append([name, cate])\n",
    "\n",
    "        # 06 get NER from whole article\n",
    "        ner_dict = {i[0]: i[1] for i in Counter(ners).most_common(20)}\n",
    "        for ner in ner_dict:\n",
    "            name = ner.split('/')[0]  # Jessica Miller\n",
    "            cate = self.ner_dict[ner.split('/')[1]]  # PERSON\n",
    "            events.append([name, cate])\n",
    "\n",
    "        # 07 get all NER entity co-occurrence information\n",
    "        # here ner_dict is from above 06\n",
    "        co_dict = self.collect_coexist(ner_sents, list(ner_dict.keys()))\n",
    "        co_events = [[i.split('@')[0].split(\n",
    "            '/')[0], i.split('@')[1].split('/')[0]] for i in co_dict]\n",
    "        events += co_events\n",
    "\n",
    "        # 08 show event graph\n",
    "        self.graph_shower.create_page(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphShow():\n",
    "    \"\"\"\"Create demo page\"\"\"\n",
    "    def __init__(self):\n",
    "        self.base = '''\n",
    "    <html>\n",
    "    <head>\n",
    "      <script type=\"text/javascript\" src=\"VIS/dist/vis.js\"></script>\n",
    "      <link href=\"VIS/dist/vis.css\" rel=\"stylesheet\" type=\"text/css\">\n",
    "      <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n",
    "    </head>\n",
    "    <body>\n",
    "    <div id=\"VIS_draw\"></div>\n",
    "    <script type=\"text/javascript\">\n",
    "      var nodes = data_nodes;\n",
    "      var edges = data_edges;\n",
    "      var container = document.getElementById(\"VIS_draw\");\n",
    "      var data = {\n",
    "        nodes: nodes,\n",
    "        edges: edges\n",
    "      };\n",
    "      var options = {\n",
    "          nodes: {\n",
    "              shape: 'circle',\n",
    "              size: 15,\n",
    "              font: {\n",
    "                  size: 15\n",
    "              }\n",
    "          },\n",
    "          edges: {\n",
    "              font: {\n",
    "                  size: 10,\n",
    "                  align: 'center'\n",
    "              },\n",
    "              color: 'red',\n",
    "              arrows: {\n",
    "                  to: {enabled: true, scaleFactor: 1.2}\n",
    "              },\n",
    "              smooth: {enabled: true}\n",
    "          },\n",
    "          physics: {\n",
    "              enabled: true\n",
    "          }\n",
    "      };\n",
    "      var network = new vis.Network(container, data, options);\n",
    "    </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    '''\n",
    "    \n",
    "\n",
    "    def create_page(self, events):\n",
    "        \"\"\"Read data\"\"\"\n",
    "        nodes = []\n",
    "        for event in events:\n",
    "            nodes.append(event[0])\n",
    "            nodes.append(event[1])\n",
    "        node_dict = {node: index for index, node in enumerate(nodes)}\n",
    "\n",
    "        data_nodes = []\n",
    "        data_edges = []\n",
    "        for node, id in node_dict.items():\n",
    "            data = {}\n",
    "            data[\"group\"] = 'Event'\n",
    "            data[\"id\"] = id\n",
    "            data[\"label\"] = node\n",
    "            data_nodes.append(data)\n",
    "\n",
    "        for edge in events:\n",
    "            data = {}\n",
    "            data['from'] = node_dict.get(edge[0])\n",
    "            data['label'] = ''\n",
    "            data['to'] = node_dict.get(edge[1])\n",
    "            data_edges.append(data)\n",
    "\n",
    "        self.create_html(data_nodes, data_edges)\n",
    "        return\n",
    "\n",
    "    def create_html(self, data_nodes, data_edges):\n",
    "        \"\"\"Generate html file\"\"\"\n",
    "        f = open('graph_show.html', 'w+')\n",
    "        html = self.base.replace('data_nodes', str(data_nodes)).replace('data_edges', str(data_edges))\n",
    "        f.write(html)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = corona_df_risk_covid.at[11821,'text_body' ]\n",
    "Miner = NewsMining()\n",
    "Miner.main(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using h_index as a factor for ranking the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'doc_id', 'source', 'title', 'abstract', 'text_body',\n",
       "       'index', 'count_risk', 'sha', 'source_x', 'doi', 'pmcid', 'pubmed_id',\n",
       "       'license', 'publish_time', 'authors', 'journal',\n",
       "       'Microsoft Academic Paper ID', 'WHO #Covidence', 'has_full_text',\n",
       "       'full_text_file', 'Rank', 'Sourceid', 'Title', 'Type', 'Issn', 'SJR',\n",
       "       'SJR Best Quartile', 'H index', 'Total Docs. (2018)',\n",
       "       'Total Docs. (3years)', 'Total Refs.', 'Total Cites (3years)',\n",
       "       'Citable Docs. (3years)', 'Cites / Doc. (2years)', 'Ref. / Doc.',\n",
       "       'Country', 'Publisher', 'Coverage', 'Categories'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h_index = pd.read_csv('/Users/u6066091/Downloads/scimagoj_2018.csv',sep = ';')\n",
    "# journal_h_index = list(corona_df_risk_covid[corona_df_risk_covid['journal'].isin(h_index['Title'])]['journal'].unique())\n",
    "corona_df_risk_smoke.join(h_index, lsuffix='journal', rsuffix='Title').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h_index[h_index['Title'].isin(journal_h_index)]['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rank', 'Sourceid', 'Title', 'Type', 'Issn', 'SJR', 'SJR Best Quartile',\n",
       "       'H index', 'Total Docs. (2018)', 'Total Docs. (3years)', 'Total Refs.',\n",
       "       'Total Cites (3years)', 'Citable Docs. (3years)',\n",
       "       'Cites / Doc. (2years)', 'Ref. / Doc.', 'Country', 'Publisher',\n",
       "       'Coverage', 'Categories'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_index.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_df_risk_covid.sort_values('count_risk', ascending = False).to_csv('/Users/u6066091/Desktop/kaggle/output/corona_challenge/curated/risk_covid.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch_pretrained_bert \n",
    "# !pip install pytorch_transformers\n",
    "# !pip install scispacy\n",
    "# !pip install bert_tokenizer\n",
    "# !pip install -q keras\n",
    "# !pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 405M/405M [02:01<00:00, 3.32MB/s] \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding sentences using BERT\n",
    "embed = []\n",
    "for i in corona_df_risk_covid['abstract']:\n",
    "    sentence_embeddings = model.encode(i)\n",
    "    embed.append(sentence_embeddings)\n",
    "# it took 20 min for 72 records    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [embed[ii][0:60] for ii in range(len(embed))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4423680 into shape (72,46080)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-492-e64077ac0ed9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# fit kmeans object to data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0membed_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0membed_resh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m72\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m768\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# print location of clusters learned by kmeans object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4423680 into shape (72,46080)"
     ]
    }
   ],
   "source": [
    "# import KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "# create kmeans object\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "# fit kmeans object to data\n",
    "embed_np = np.array(data)\n",
    "embed_resh = embed_np.reshape(72,60*768 )\n",
    "kmeans.fit(embed_res)\n",
    "# print location of clusters learned by kmeans object\n",
    "print(kmeans.cluster_centers_)\n",
    "# # save new clusters for chart\n",
    "y_km = kmeans.predict(embed_resh)\n",
    "plt.scatter(embed_resh[y_km ==0,0], embed_resh[y_km == 0,1], s=100, c='red')\n",
    "plt.scatter(embed_resh[y_km ==1,0], embed_resh[y_km == 1,1], s=100, c='cyan')\n",
    "\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X, y_true = make_blobs(n_samples=300, centers=4,\n",
    "                       cluster_std=0.60, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-436-aa27f39ad778>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "embed.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.', \n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "sentence_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n",
    "from pytorch_transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:16<00:00, 13948.12B/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length, \n",
    "                t_max_len=30, q_max_len=239, a_max_len=239):\n",
    "#     import BertTokenizer\n",
    "#     tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    \n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "        \n",
    "        t = t[:t_new_len]\n",
    "        q = q[:q_new_len]\n",
    "        a = a[:a_new_len]\n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
    "    input_masks = _get_masks(stoken, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken, max_sequence_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def compute_input_arays(df, columns, tokenizer, max_sequence_length):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for _, instance in (df[columns].iterrows()):\n",
    "        t, q, a = instance.question_title, instance.question_body, instance.answer\n",
    "\n",
    "        t, q, a = _trim_input(t, q, a, max_sequence_length)\n",
    "\n",
    "        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "        \n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "            np.asarray(input_masks, dtype=np.int32), \n",
    "            np.asarray(input_segments, dtype=np.int32)]\n",
    "\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])\n",
    "# 3. Create model\n",
    "# compute_spearmanr() is used to compute the competition metric for the validation set\n",
    "\n",
    "# CustomCallback() is a class which inherits from tf.keras.callbacks.Callback and will compute and append validation score and validation/test predictions respectively, after each epoch.\n",
    "\n",
    "# bert_model() contains the actual architecture that will be used to finetune BERT to our dataset. It's simple, just taking the sequence_output of the bert_layer and pass it to an AveragePooling layer and finally to an output layer of 30 units (30 classes that we have to predict)\n",
    "\n",
    "# train_and_predict() this function will be run to train and obtain predictions\n",
    "\n",
    "def compute_spearmanr(trues, preds):\n",
    "    rhos = []\n",
    "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n",
    "    return np.mean(rhos)\n",
    "\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, valid_data, test_data, batch_size=16, fold=None):\n",
    "\n",
    "        self.valid_inputs = valid_data[0]\n",
    "        self.valid_outputs = valid_data[1]\n",
    "        self.test_inputs = test_data\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.valid_predictions = []\n",
    "        self.test_predictions = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.valid_predictions.append(\n",
    "            self.model.predict(self.valid_inputs, batch_size=self.batch_size))\n",
    "        \n",
    "        rho_val = compute_spearmanr(\n",
    "            self.valid_outputs, np.average(self.valid_predictions, axis=0))\n",
    "        \n",
    "        print(\"\\nvalidation rho: %.4f\" % rho_val)\n",
    "        \n",
    "        if self.fold is not None:\n",
    "            self.model.save_weights(f'bert-base-{fold}-{epoch}.h5py')\n",
    "        \n",
    "        self.test_predictions.append(\n",
    "            self.model.predict(self.test_inputs, batch_size=self.batch_size)\n",
    "        )\n",
    "\n",
    "def bert_model():\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    input_segments = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n",
    "    \n",
    "    bert_layer = hub.KerasLayer(BERT_PATH, trainable=True)\n",
    "    \n",
    "    _, sequence_output = bert_layer([input_word_ids, input_masks, input_segments])\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[input_word_ids, input_masks, input_segments], outputs=out)\n",
    "    \n",
    "    return model    \n",
    "        \n",
    "def train_and_predict(model, train_data, valid_data, test_data, \n",
    "                      learning_rate, epochs, batch_size, loss_function, fold):\n",
    "        \n",
    "    custom_callback = CustomCallback(\n",
    "        valid_data=(valid_data[0], valid_data[1]), \n",
    "        test_data=test_data,\n",
    "        batch_size=batch_size,\n",
    "        fold=None)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=loss_function, optimizer=optimizer)\n",
    "    model.fit(train_data[0], train_data[1], epochs=epochs, \n",
    "              batch_size=batch_size, callbacks=[custom_callback])\n",
    "    \n",
    "    return custom_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screening for smoke related risk factor\n",
    "smoke_ind = []\n",
    "\n",
    "for i in corona_df['abstract']:\n",
    "    if ((str(i).lower().find('smok') != -1) or (str(i).lower().find('pulmo') != -1)):\n",
    "    \n",
    "        smoke_ind.append(i)\n",
    "\n",
    "corona_df_smoke = corona_df[corona_df['abstract'].isin(smoke_ind)]       \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text_body</th>\n",
       "      <th>count_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6599ebbef3d868afac9daa4f80fa075675cf03bc</td>\n",
       "      <td>BIORXIV</td>\n",
       "      <td>International aviation emissions to 2025: Can ...</td>\n",
       "      <td>International aviation is growing rapidly, res...</td>\n",
       "      <td>Sixty years ago, civil aviation was an infant ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45e7c863c8a0bf2f373a64c3d7ba1546ca26d672</td>\n",
       "      <td>BIORXIV</td>\n",
       "      <td>Airborne bioaerosols and their impact on human...</td>\n",
       "      <td>Bioaerosols consist of aerosols originated bio...</td>\n",
       "      <td>Bioaerosols are very small airborne particles ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62bf1af0ca05d3fdd4eea15b337d389713a387bc</td>\n",
       "      <td>BIORXIV</td>\n",
       "      <td>AN EMERGENCY MEDICAL SERVICES TRANSFER AUTHORI...</td>\n",
       "      <td>Objective. To describe the rapid development a...</td>\n",
       "      <td>Conclusions. Rapid establishment of an EMS-bas...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1af946e7a63239d9b462e126f98d0cd6d24df4bd</td>\n",
       "      <td>BIORXIV</td>\n",
       "      <td>Respiratory viral coinfection and disease seve...</td>\n",
       "      <td>Background: With advent of molecular diagnosti...</td>\n",
       "      <td>etiological agents involved in such cases [1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6c806034d4e17f1e43b7415c9c906c8160622694</td>\n",
       "      <td>BIORXIV</td>\n",
       "      <td>Spatial-temporal transmission of influenza and...</td>\n",
       "      <td>Cities and urban areas play an important role ...</td>\n",
       "      <td>Every year in the United States, influenza (co...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19979</th>\n",
       "      <td>8780e9524d9271a7b8e789f0f8c4eb6860ca8c50</td>\n",
       "      <td>BIORXIV</td>\n",
       "      <td>Avian viral surveillance in Victoria, Australi...</td>\n",
       "      <td>Viruses in avian hosts can pose threats to avi...</td>\n",
       "      <td>Introduction Avian species serve as hosts for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>05f2d4c337413ae496e31e2259020f3e328dcfa1</td>\n",
       "      <td>BIORXIV</td>\n",
       "      <td>Recombinase Polymerase Amplification Assay for...</td>\n",
       "      <td>Over 2.5 billion people are exposed to the ris...</td>\n",
       "      <td>Dengue virus (DENV) is a mosquito-transmitted ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>b38f3c83aaa3fa7c8f5c87af266793afcbd11c86</td>\n",
       "      <td>COMMON_USE_SUB</td>\n",
       "      <td>Prediction of criticality in patients with sev...</td>\n",
       "      <td>We screened the electronic records of 2,799 pa...</td>\n",
       "      <td>The outbreaks of COVID-19 epidemic has caused ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>6efe01046ce81279412ea440a4b246f942f29124</td>\n",
       "      <td>COMMON_USE_SUB</td>\n",
       "      <td>Systematic Review of the Registered Clinical T...</td>\n",
       "      <td>Background: Since the outbreak of coronavirus ...</td>\n",
       "      <td>This review presented a narrative synthesis. T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0562f70516579d557cd1486000bb7aac5ccec2a1</td>\n",
       "      <td>COMMON_USE_SUB</td>\n",
       "      <td>Association of Cardiovascular Manifestations w...</td>\n",
       "      <td>Background: The outbreaks of coronavirus disea...</td>\n",
       "      <td>As clinic experiences increases, clinicians be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2125 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         doc_id          source  \\\n",
       "0      6599ebbef3d868afac9daa4f80fa075675cf03bc         BIORXIV   \n",
       "3      45e7c863c8a0bf2f373a64c3d7ba1546ca26d672         BIORXIV   \n",
       "5      62bf1af0ca05d3fdd4eea15b337d389713a387bc         BIORXIV   \n",
       "25     1af946e7a63239d9b462e126f98d0cd6d24df4bd         BIORXIV   \n",
       "31     6c806034d4e17f1e43b7415c9c906c8160622694         BIORXIV   \n",
       "...                                         ...             ...   \n",
       "19979  8780e9524d9271a7b8e789f0f8c4eb6860ca8c50         BIORXIV   \n",
       "19980  05f2d4c337413ae496e31e2259020f3e328dcfa1         BIORXIV   \n",
       "19989  b38f3c83aaa3fa7c8f5c87af266793afcbd11c86  COMMON_USE_SUB   \n",
       "19990  6efe01046ce81279412ea440a4b246f942f29124  COMMON_USE_SUB   \n",
       "19999  0562f70516579d557cd1486000bb7aac5ccec2a1  COMMON_USE_SUB   \n",
       "\n",
       "                                                   title  \\\n",
       "0      International aviation emissions to 2025: Can ...   \n",
       "3      Airborne bioaerosols and their impact on human...   \n",
       "5      AN EMERGENCY MEDICAL SERVICES TRANSFER AUTHORI...   \n",
       "25     Respiratory viral coinfection and disease seve...   \n",
       "31     Spatial-temporal transmission of influenza and...   \n",
       "...                                                  ...   \n",
       "19979  Avian viral surveillance in Victoria, Australi...   \n",
       "19980  Recombinase Polymerase Amplification Assay for...   \n",
       "19989  Prediction of criticality in patients with sev...   \n",
       "19990  Systematic Review of the Registered Clinical T...   \n",
       "19999  Association of Cardiovascular Manifestations w...   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      International aviation is growing rapidly, res...   \n",
       "3      Bioaerosols consist of aerosols originated bio...   \n",
       "5      Objective. To describe the rapid development a...   \n",
       "25     Background: With advent of molecular diagnosti...   \n",
       "31     Cities and urban areas play an important role ...   \n",
       "...                                                  ...   \n",
       "19979  Viruses in avian hosts can pose threats to avi...   \n",
       "19980  Over 2.5 billion people are exposed to the ris...   \n",
       "19989  We screened the electronic records of 2,799 pa...   \n",
       "19990  Background: Since the outbreak of coronavirus ...   \n",
       "19999  Background: The outbreaks of coronavirus disea...   \n",
       "\n",
       "                                               text_body  count_risk  \n",
       "0      Sixty years ago, civil aviation was an infant ...           1  \n",
       "3      Bioaerosols are very small airborne particles ...           1  \n",
       "5      Conclusions. Rapid establishment of an EMS-bas...           2  \n",
       "25     etiological agents involved in such cases [1, ...           2  \n",
       "31     Every year in the United States, influenza (co...           5  \n",
       "...                                                  ...         ...  \n",
       "19979  Introduction Avian species serve as hosts for ...           1  \n",
       "19980  Dengue virus (DENV) is a mosquito-transmitted ...           1  \n",
       "19989  The outbreaks of COVID-19 epidemic has caused ...           2  \n",
       "19990  This review presented a narrative synthesis. T...           1  \n",
       "19999  As clinic experiences increases, clinicians be...           1  \n",
       "\n",
       "[2125 rows x 6 columns]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corona_df_risk[~corona_df_risk.isin(corona_df_smoke)].dropna()\n",
    "# len(smoke_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_df_smoke = corona_df_smoke.dropna()\n",
    "corona_df_smoke.to_csv('/Users/u6066091/Desktop/kaggle/output/corona_challenge/smoke_pulmo_full_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screening for pregnancy/baby\n",
    "baby_ind = []\n",
    "\n",
    "for i in corona_df['text_body']:\n",
    "    if ((str(i).lower().find('pregn') != -1) or (str(i).lower().find('baby') != -1) or str(i).lower().find('infant') != -1\n",
    "         or (str(i).lower().find('new born') != -1)):\n",
    "    \n",
    "        baby_ind.append(i)\n",
    "\n",
    "corona_df_baby = corona_df[corona_df['text_body'].isin(baby_ind)]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_df_baby = corona_df_baby.drop_duplicates(['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_df_baby.to_csv('/Users/u6066091/Desktop/kaggle/output/corona_challenge/baby_pregnant.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_df_baby.sample(10).to_csv('/Users/u6066091/Desktop/kaggle/output/corona_challenge/baby_morvarid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COMMON_USE_SUB'], dtype=object)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corona_df_nosomek.sample(10,random_state=40)\n",
    "corona_df_nosomek.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = corona_df.loc[1,'title']\n",
    "res = i.find('seq')\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the library with the CountVectorizer method\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x667.491 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Helper function\n",
    "def plot_10_most_common_words(count_data, count_vectorizer):\n",
    "    import matplotlib.pyplot as plt\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    total_counts = np.zeros(len(words))\n",
    "    for t in count_data:\n",
    "        total_counts+=t.toarray()[0]\n",
    "    \n",
    "    count_dict = (zip(words, total_counts))\n",
    "    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:20]\n",
    "    words = [w[0] for w in count_dict]\n",
    "    counts = [w[1] for w in count_dict]\n",
    "    x_pos = np.arange(len(words)) \n",
    "    \n",
    "    plt.figure(2, figsize=(15, 15/1.6180))\n",
    "    plt.subplot(title='10 most common words')\n",
    "    sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n",
    "    sns.barplot(x_pos, counts, palette='husl')\n",
    "    plt.xticks(x_pos, words, rotation=90) \n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('counts')\n",
    "    plt.show()\n",
    "# Initialise the count vectorizer with the English stop words\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 1), max_df =0.7)\n",
    "# Fit and transform the processed titles\n",
    "count_data = count_vectorizer.fit_transform(corona_df['text_body'])\n",
    "# Visualise the 10 most common words\n",
    "plot_10_most_common_words(count_data, count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found via LDA:\n",
      "\n",
      "Topic #0:\n",
      "sequences sequence viruses model species figure genome samples rna viral pcr transmission preprint host strains gene fig cases new doi\n",
      "\n",
      "Topic #1:\n",
      "et al genes dogs gene expression protein cell cats 2013 2012 figure 2014 cells 2011 significant 2015 proteins identified levels\n",
      "\n",
      "Topic #2:\n",
      "cells protein cell viral proteins fig rna figure binding activity expression replication ml infected anti membrane mm viruses cov assay\n",
      "\n",
      "Topic #3:\n",
      "cells mice cell il immune infected expression response ifn viral vaccine responses group levels fig antibody against anti figure animals\n",
      "\n",
      "Topic #4:\n",
      "patients health influenza respiratory cases clinical who risk age children patient infections years public days group will treatment hospital among\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "# Load the LDA model from sk-learn\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    " \n",
    "# Helper function\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        \n",
    "# Tweak the two parameters below\n",
    "number_topics = 5\n",
    "number_words = 20\n",
    "# Create and fit the LDA model\n",
    "lda = LDA(n_components=number_topics, n_jobs=-1)\n",
    "lda.fit(count_data)\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/u6066091/Library/Caches/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414/pyLDAvis-2.1.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: future in /opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (1.4.1)\n",
      "Requirement already satisfied: pytest in /opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (5.3.5)\n",
      "Collecting funcy\n",
      "  Downloading funcy-1.14.tar.gz (548 kB)\n",
      "\u001b[K     |████████████████████████████████| 548 kB 182 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2>=2.7.2 in /opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (2.11.1)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.34.2)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.14.1)\n",
      "Requirement already satisfied: numexpr in /opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (2.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (1.8.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (20.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (0.1.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (1.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.7/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from packaging->pytest->pyLDAvis) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from packaging->pytest->pyLDAvis) (1.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->pyLDAvis) (2.2.0)\n",
      "Building wheels for collected packages: funcy\n",
      "  Building wheel for funcy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32042 sha256=f0524d107ac9f87f88b1696d6b453d84f0e3915844c7778b98fe1098a9d311ea\n",
      "  Stored in directory: /Users/u6066091/Library/Caches/pip/wheels/3c/33/97/805b282e129f60bb4e87cea622338f30b65f21eaf65219971f\n",
      "Successfully built funcy\n",
      "Installing collected packages: funcy, pyLDAvis\n",
      "Successfully installed funcy-1.14 pyLDAvis-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 15s, sys: 3.25 s, total: 3min 18s\n",
      "Wall time: 3min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2      0.136838  0.034965       1        1  28.561993\n",
       "4     -0.175472 -0.083036       2        1  25.407176\n",
       "0     -0.111001  0.088936       3        1  21.305861\n",
       "3      0.105380 -0.125554       4        1  15.956257\n",
       "1      0.044255  0.084689       5        1   8.768714, topic_info=             Term           Freq          Total Category  logprob  loglift\n",
       "135574         et   97782.000000   97782.000000  Default  30.0000  30.0000\n",
       "47446          al   99143.000000   99143.000000  Default  29.0000  29.0000\n",
       "87721       cells  218352.000000  218352.000000  Default  28.0000  28.0000\n",
       "229297       mice   60079.000000   60079.000000  Default  27.0000  27.0000\n",
       "266585   patients   90558.000000   90558.000000  Default  26.0000  26.0000\n",
       "...           ...            ...            ...      ...      ...      ...\n",
       "163066      group    4711.576249   52741.665094   Topic5  -6.4152   0.0186\n",
       "87721       cells    5252.263884  218352.660752   Topic5  -6.3066  -1.2935\n",
       "312698    samples    4563.136267   57644.707440   Topic5  -6.4472  -0.1023\n",
       "187226  increased    4403.372618   36531.895261   Topic5  -6.4829   0.3182\n",
       "328189    species    4379.540544   33119.647190   Topic5  -6.4883   0.4108\n",
       "\n",
       "[534 rows x 6 columns], token_table=        Topic      Freq   Term\n",
       "term                          \n",
       "4185        1  0.470378    100\n",
       "4185        2  0.170010    100\n",
       "4185        3  0.144989    100\n",
       "4185        4  0.179763    100\n",
       "4185        5  0.034861    100\n",
       "...       ...       ...    ...\n",
       "377972      1  0.018916  years\n",
       "377972      2  0.814565  years\n",
       "377972      3  0.109827  years\n",
       "377972      4  0.025322  years\n",
       "377972      5  0.031390  years\n",
       "\n",
       "[1528 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 5, 1, 4, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "LDAvis_data_filepath = os.path.join('./ldavis_prepared_'+str(number_topics))\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "# if 1 == 1:\n",
    "LDAvis_prepared = sklearn_lda.prepare(lda, count_data, count_vectorizer)\n",
    "#     with open(LDAvis_data_filepath, 'w') as f:\n",
    "#         pickle.dump(LDAvis_prepared, f)\n",
    "        \n",
    "# # load the pre-prepared pyLDAvis data from disk\n",
    "# with open(LDAvis_data_filepath) as f:\n",
    "#     LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './ldavis_prepared_'+ str(number_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles retrieved from biorxiv: 803\n"
     ]
    }
   ],
   "source": [
    "biorxiv_dir = '/Users/u6066091/Desktop/kaggle/input/corona_challenge/biorxiv_medrxiv/'\n",
    "filenames = os.listdir(biorxiv_dir)\n",
    "print(\"Number of articles retrieved from biorxiv:\", len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles retrieved from pmc_custom_license: 787\n"
     ]
    }
   ],
   "source": [
    "pmc_custom_license = '/Users/u6066091/Desktop/kaggle/input/corona_challenge/pmc_custom_license/'\n",
    "filenames = os.listdir(pmc_custom_license)\n",
    "print(\"Number of articles retrieved from pmc_custom_license:\", len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "\n",
    "for filename in filenames:\n",
    "    filename = pmc_custom_license + filename\n",
    "    file = json.load(open(filename, 'rb'))\n",
    "    all_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multimerization of HIV-1 integrase hinges on conserved SH3-docking platforms'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[0]['metadata']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary keys: dict_keys(['paper_id', 'metadata', 'abstract', 'body_text', 'bib_entries', 'ref_entries', 'back_matter'])\n"
     ]
    }
   ],
   "source": [
    "file = all_files[0]\n",
    "print(\"Dictionary keys:\", file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function\n",
    "\n",
    "def format_name(author):\n",
    "    middle_name = \" \".join(author['middle'])\n",
    "    \n",
    "    if author['middle']:\n",
    "        return \" \".join([author['first'], middle_name, author['last']])\n",
    "    else:\n",
    "        return \" \".join([author['first'], author['last']])\n",
    "\n",
    "\n",
    "def format_affiliation(affiliation):\n",
    "    text = []\n",
    "    location = affiliation.get('location')\n",
    "    if location:\n",
    "        text.extend(list(affiliation['location'].values()))\n",
    "    \n",
    "    institution = affiliation.get('institution')\n",
    "    if institution:\n",
    "        text = [institution] + text\n",
    "    return \", \".join(text)\n",
    "\n",
    "def format_authors(authors, with_affiliation=False):\n",
    "    name_ls = []\n",
    "    \n",
    "    for author in authors:\n",
    "        name = format_name(author)\n",
    "        if with_affiliation:\n",
    "            affiliation = format_affiliation(author['affiliation'])\n",
    "            if affiliation:\n",
    "                name_ls.append(f\"{name} ({affiliation})\")\n",
    "            else:\n",
    "                name_ls.append(name)\n",
    "        else:\n",
    "            name_ls.append(name)\n",
    "    \n",
    "    return \", \".join(name_ls)\n",
    "\n",
    "def format_body(body_text):\n",
    "    texts = [(di['section'], di['text']) for di in body_text]\n",
    "    texts_di = {di['section']: \"\" for di in body_text}\n",
    "    \n",
    "    for section, text in texts:\n",
    "        texts_di[section] += text\n",
    "\n",
    "    body = \"\"\n",
    "\n",
    "    for section, text in texts_di.items():\n",
    "        body += section\n",
    "        body += \"\\n\\n\"\n",
    "        body += text\n",
    "        body += \"\\n\\n\"\n",
    "    \n",
    "    return body\n",
    "\n",
    "def format_bib(bibs):\n",
    "    if type(bibs) == dict:\n",
    "        bibs = list(bibs.values())\n",
    "    bibs = deepcopy(bibs)\n",
    "    formatted = []\n",
    "    \n",
    "    for bib in bibs:\n",
    "        bib['authors'] = format_authors(\n",
    "            bib['authors'], \n",
    "            with_affiliation=False\n",
    "        )\n",
    "        formatted_ls = [str(bib[k]) for k in ['title', 'authors', 'venue', 'year']]\n",
    "        formatted.append(\", \".join(formatted_ls))\n",
    "\n",
    "    return \"; \".join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_files = []\n",
    "for file in all_files:\n",
    "    features = [\n",
    "        file['paper_id'],\n",
    "        file['metadata']['title'],\n",
    "        format_authors(file['metadata']['authors']),\n",
    "        format_authors(file['metadata']['authors'], \n",
    "                       with_affiliation=True),\n",
    "        format_body(file['abstract']),\n",
    "        format_body(file['body_text']),\n",
    "        format_bib(file['bib_entries']),\n",
    "        file['metadata']['authors'],\n",
    "        file['bib_entries']\n",
    "    ]\n",
    "    cleaned_files.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n20-kb insert library preparation protocol (https://www.pacb.com/wp-content/uploads/ Procedure-Checklist-20-kb-Template-Preparation-Using-BluePippin-Size-Selection -System.pdf). The 20-kb library was sequenced with a PacBio RS II platform using two single-molecule real-time (SMRT) cells, resulting in 283,436 total reads and an average read length of 7,600 bp. Reads were subsequently assessed for quality using FastQC (https://www.bioinformatics.babraham.ac.uk/projects/fastqc/).Whole-genome assemblies were generated using PacBio SMRT Analysis v. 2.3.0 and Canu v. 1.5 (28) software. The average PacBio coverage for the assembled genome was 475ϫ. Assembling the PacBio data resulted in a fully sequenced closed circular chromosome, which was subsequently oriented to start at the dnaA gene and trimmed by removing any overlapping sequence. The genome was then polished and error corrected using the Broad Institute's Pilon v. 1.18 software (29) along with the Illumina GAIIx 3,474,442 paired-end sequencing reads, which were previously used for the draft assembly (26) . Default parameters were used for all software. The closed KM22 genome was then annotated using NCBI's Prokaryotic Genome Annotation Pipeline (PGAP) (30) . The complete genome of KM22 consists of 5,205,646 bp with a GϩC content of 68.2%, a total of 4,827 predicted protein coding sequences (CDSs), 9 rRNA operons, 1 transfermessenger RNA (tmRNA), 3 noncoding RNAs (ncRNAs), and 56 tRNAs.Data availability. The whole-genome sequence for Bordetella bronchiseptica isolate KM22 was deposited in DDBJ/ENA/GenBank under the accession number CP022962. The PacBio read data were deposited in the NCBI Sequence Read Archive (SRA) under BioProject accession number PRJNA398562 and SRA study accession number SRP222122 (run numbers SRR10134673 and SRR10134672). Illumina HiSeq short read sequences have been deposited at the European Nucleotide Archive under accession number ERS027415.\\n\\nACKNOWLEDGMENTS\\n\\nWe thank the Yale University Center for Genome Analysis for their assistance in producing the PacBio sequence data.Funding for this research was provided by the USDA Agricultural Research Service. Funding sources did not impact study design, data collection, data analysis, decisions on publication, or preparation of the manuscript.Mention of trade names or commercial products in this article is solely for the purpose of providing specific information and does not imply recommendation or endorsement by the U.S. Department of Agriculture.\\n\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [\n",
    "    'paper_id', \n",
    "    'title', \n",
    "    'authors',\n",
    "    'affiliations', \n",
    "    'abstract', \n",
    "    'text', \n",
    "    'bibliography',\n",
    "    'raw_authors',\n",
    "    'raw_bibliography'\n",
    "]\n",
    "\n",
    "clean_df = pd.DataFrame(cleaned_files, columns=col_names)\n",
    "clean_df.loc[0,'text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
